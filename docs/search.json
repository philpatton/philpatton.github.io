[
  {
    "objectID": "occ.html",
    "href": "occ.html",
    "title": "Occupancy models",
    "section": "",
    "text": "In this notebook, I demonstrate how to fit static site-occupancy models in PyMC (Royle and Dorazio 2008, chap. 3). The standard site-occupancy model models binary detection/non-detection data \\(y_{j,k}\\) for repeated surveys \\(k=1,2,\\dots,K\\) at sites \\(j=1,2,\\dots,J.\\) The species is present at the sites when \\(z_j=1,\\) and absent otherwise. We assume that our probability of detecting the species given that the site is occupied is \\(P(y_{j,k}|z_j=1)=p,\\) and zero when the site is unoccupied. The probability of occurrence, which is typically the parameter of interest, is \\(P(z_{j}=1)=\\psi.\\) As such, we can think of this as a zero-inflated binomial model, where \\[\n\\begin{align}\n&y_j \\sim\n\\begin{cases}\n    0,   & \\text{if } z_j = 0 \\\\\n    \\text{Binomial}(K, p),   & \\text{if } z_j = 1\n\\end{cases} \\\\\n&z_j \\sim \\text{Bernoulli}(\\psi)\n\\end{align},\n\\] which assumes a constant occurrence probability across sites and a constant detection probability. I start with this simple model, then add site- and visit-level covariates later.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occ.html#estimating-parameters-with-pymc",
    "href": "occ.html#estimating-parameters-with-pymc",
    "title": "Occupancy models",
    "section": "Estimating parameters with PyMC",
    "text": "Estimating parameters with PyMC\nNext, I use PyMC to train the occupancy model with the simulated data. First, similar to JAGS and Stan, the model must be specified using the PyMC syntax. This is done using a context manager in Python, essentially, a with statement. This creates a Model object.\n\nwith pm.Model() as constant:\n\n    # priors for the detetion and occurrence probabilities\\\n    psi = pm.Uniform('psi', 0, 1)\n    p = pm.Uniform('p', 0, 1)\n\n    # likelihood for the summarized data\n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=visit_count, \n                            observed=y_summarized)\n\nIn JAGS, the prior for \\(p\\) would be specified as p ~ dunif(0, 1). The PyMC equivalent is p = pm.Uniform('p', 0, 1). This could, alternatively, be specified as p = pm.Uniform('detection probability', 0, 1). For the likelihood, I use PyMC’s built-in ZeroInflatedBinomial distribution. We tell PyMC that this is an observed random variable by supplying data to the observed argument. PyMC also has handy tools for visualizing the model.\n\npm.model_to_graphviz(constant)\n\n\n\n\n\n\n\nFigure 1: Visual representation of model \\(p(\\cdot)\\psi(\\cdot).\\) MarginalMixture refers to the zero-inflated binomial distribution.\n\n\n\n\n\nNow I can sample from the posterior. Again, I use the context manager, this time referring to the model by name. It’s typical to name the output with idata because, by default, PyMC returns an object of class InferenceData from the Arviz package. Arviz is similar to the coda package for R.\n\nwith constant:\n    constant_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, p]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nPyMC will try to use the No-U-Turn Sampler (NUTS) whenever possible. As you can see, it samples the posterior quickly. I can plot the output using the az.plot_trace(), supplying the true values for \\(p\\) and \\(\\psi\\) for comparizon. I can also look at a tabular summary using az.summary().\n\naz.plot_trace(\n    constant_idata,\n    compact=True,\n    figsize=(8,4),\n    lines=[(\"psi\", {}, [psi_true]), (\"p\", {}, [p_true])] \n);\n\n\n\n\n\n\n\nFigure 2: Traceplots for the \\(p(\\cdot)\\psi(\\cdot)\\) model. The true parameter values are shown by vertical and horizontal lines.\n\n\n\n\n\n\naz.summary(constant_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npsi\n0.802\n0.042\n0.725\n0.882\n0.001\n0.001\n2503.0\n2663.0\n1.0\n\n\np\n0.498\n0.030\n0.442\n0.554\n0.001\n0.000\n2042.0\n2089.0\n1.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occ.html#adding-site-covariates",
    "href": "occ.html#adding-site-covariates",
    "title": "Occupancy models",
    "section": "Adding site covariates",
    "text": "Adding site covariates\nNext, I add in some realism by simulating a site-level covariate \\(x\\) that affects the occurrence probability. I model this effect with a logit-linear model, i.e., \\(\\psi_j=\\text{logit}^{-1}(\\beta_0 + \\beta_1 x_j).\\)\n\n## ecological model\n\n# true parameter values\nbeta0_true = -1\nbeta1_true = 3\n\n# covariates \nx = scale(rng.uniform(size=site_count))\n\n# linear model\nmu_true = beta0_true + beta1_true * x\npsi_true = invlogit(mu_true)\n\n# simulate occurrence state\nz_true = rng.binomial(1, psi_true)\n\n## detection model\n\n# true parameter values\np_true = 0.75\n\n# simulate detection\ny = sim_y(p_true, z_true, site_count, visit_count)\n\n# vector with the number of detections at each site \ny_summarized = y.sum(axis=1)\n\n# detection data at the first five sites \ny[:5]\n\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]])\n\n\nAgain, I specify the model with PyMC. Like JAGS, the random variables can be manipulated, as in a linear model with \\(x_j.\\) These behave like numpy arrays, meaning that vectorized operations and broadcasting are available. To monitor the output of these manipulations, use the pm.Deterministic class. In this case, I am monitoring the site level occurrence probability \\(\\psi_j.\\)\n\nwith pm.Model() as psix:\n\n    # occurrence process \n    # priors \n    beta0 = pm.Normal(\"beta0\", mu=0, sigma=2)\n    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n    \n    # linear model\n    mu = beta0 + beta1 * x\n    psi = pm.Deterministic(\"psi\", pm.math.invlogit(mu))\n\n    # detection process\n    # prior\n    p = pm.Uniform('p', 0, 1)\n\n    # likelihood for the summarized data\n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=visit_count, \n                            observed=y_summarized)\n\npm.model_to_graphviz(psix)\n\n\n\n\n\n\n\nFigure 3: Visual representation of model \\(p(\\cdot)\\psi(x).\\) MarginalMixture refers to the zero-inflated binomial distribution.\n\n\n\n\n\n\nwith psix:\n    psix_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [beta0, beta1, p]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_trace(\n    psix_idata,\n    figsize=(8,6),\n    var_names=['beta0', 'beta1', 'p'],\n    lines=[(\"beta0\", {}, [beta0_true]), (\"beta1\", {}, [beta1_true]), \n           ('p', {}, [p_true])]\n);\n\n\n\n\nTraceplots for the \\(p(\\cdot)\\psi(x)\\) model. The true parameter values are shown by vertical and horizontal lines\n\n\n\n\n\naz.summary(psix_idata, var_names=['beta0', 'beta1', 'p'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta0\n-1.241\n0.262\n-1.723\n-0.736\n0.005\n0.004\n2503.0\n2726.0\n1.0\n\n\nbeta1\n2.852\n0.404\n2.076\n3.577\n0.008\n0.006\n2674.0\n2634.0\n1.0\n\n\np\n0.745\n0.032\n0.684\n0.803\n0.001\n0.000\n3722.0\n3020.0\n1.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occ.html#adding-visit-covariates",
    "href": "occ.html#adding-visit-covariates",
    "title": "Occupancy models",
    "section": "Adding visit covariates",
    "text": "Adding visit covariates\nFinally, I add in visit-level covariate \\(w_{j,k}\\) that affects detection.\n\n## ecological model\n\n# true parameter values\nbeta0_true = -1\nbeta1_true = 3\n\n# covariates \nx = scale(rng.uniform(size=site_count))\n\n# linear model\nmu_true = beta0_true + beta1_true * x\npsi_true = invlogit(mu_true)\n\n# simulate occurrence state\nz_true = rng.binomial(1, psi_true)\n\n# true parameter values\nalpha0_true = 1\nalpha1_true = -3\n\n# covariates\nw = rng.uniform(size=site_count * visit_count).reshape(site_count, visit_count)\nw = scale(w)\n\n# linear model\nnu_true = alpha0_true + alpha1_true * w\np_true = invlogit(nu_true)\n\n# simulate detection\ny = sim_y(p_true, z_true, site_count, visit_count)\n\ny[:5]\n\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 1, 1],\n       [1, 1, 0],\n       [0, 0, 0]])\n\n\nOur PyMC code will need to be a little uglier now. I could write the model in terms of the latent occurrence state \\(z_j.\\) The NUTS sampler, however, does not jive with discrete latent states. As such, PyMC will assign it to a binary Gibbs sampler by default, which works, albeit painfully slowly.\nSince I am impatient, I instead use the marginalized version of the model, that is, a model that does not include the discrete latent states. To do this in PyMC, I use the CustomDist class. This requires, first, defining the log probability of the distribution, logp, given the data and it’s parameters. We can write logp using the likelihood of the occupancy model, \\[\nP(\\mathbf{y}_j)=\n\\begin{cases}\n    P(\\mathbf{y}_j | z_j = 1)\\; \\psi_j \\; + \\; (1 - \\psi_j),   & \\text{if } \\mathbf{y}_j = \\mathbf{0}\\\\\n    P(\\mathbf{y}_j | z_j = 1)\\; \\psi_j,  & \\text{otherwise}\n\\end{cases}\n\\] where \\(P(\\mathbf{y}_j | z_j = 1) = \\prod_j p_{j,k}^{y_{j,k}} (1-p_{j,k})^{(1-y_{j,k})}\\) (Royle and Dorazio 2008). To do this in PyMC, I rely on the pm.math.switch function, which is similar to ifelse() in R or np.where().\n\n# likelihood for y data\ndef logp(x, p, psi):\n    '''Computes the log-likelihood for an occupancy model\n\n    Args: \n        x: (site_count x visit_count) array with binary detection data\n        p: (site_count x visit_count) array of probabilities\n        p: site_count vector of probabilities\n    '''\n    \n    bern = (p ** x) * ((1 - p) ** (1 - x))\n    bern_prod = pm.math.prod(bern, axis=1)\n    \n    res = pm.math.switch(\n        x.sum(axis=1) &gt; 0,\n        bern_prod * psi,\n        bern_prod * psi + (1 - psi)\n    )\n    \n    return pm.math.log(res)\n\nThen, I simply provide this function as an argument to the CustomDist class in our PyMC model.\n\nwith pm.Model() as marginal:\n\n    # occurrence process \n    # priors \n    beta0 = pm.Normal(\"beta0\", mu=0, sigma=2)\n    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n    \n    # linear model\n    mu = beta0 + beta1 * x\n    psi = pm.Deterministic(\"psi\", pm.math.invlogit(mu))\n\n    # detection process\n    # priors\n    alpha0 = pm.Normal('alpha0', mu=0, sigma=2)\n    alpha1 = pm.Normal('alpha1', mu=0, sigma=2)\n\n    # linear model\n    nu = alpha0 + alpha1 * w\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # likelihood\n    pm.CustomDist(\n        'y',\n        p,\n        psi,\n        logp=logp,\n        observed=y,\n    )\n\npm.model_to_graphviz(marginal)\n\n\n\n\n\n\n\nFigure 4: Visual representation of the \\(p(w)\\psi(w)\\) model.\n\n\n\n\n\n\nwith marginal:\n    marginal_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [beta0, beta1, alpha0, alpha1]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_trace(\n    marginal_idata,\n    figsize=(8,6), \n    var_names=['beta0', 'beta1', 'alpha0', 'alpha1'],\n    lines=[(\"beta0\", {}, [beta0_true]), (\"beta1\", {}, [beta1_true]), \n           ('alpha0', {}, [alpha0_true]), ('alpha1', {}, [alpha1_true])]\n);\n\n\n\n\n\n\n\nFigure 5: Tracepots for the \\(p(w)\\psi(x)\\) model. The true parameter values are shown by vertical and horizontal lines\n\n\n\n\n\n\naz.summary(marginal_idata, var_names=['beta0', 'beta1', 'alpha0', 'alpha1'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta0\n-0.743\n0.242\n-1.203\n-0.298\n0.004\n0.003\n3445.0\n3021.0\n1.0\n\n\nbeta1\n2.794\n0.397\n2.055\n3.542\n0.007\n0.005\n3073.0\n2584.0\n1.0\n\n\nalpha0\n1.398\n0.271\n0.911\n1.916\n0.005\n0.004\n2854.0\n2547.0\n1.0\n\n\nalpha1\n-3.086\n0.388\n-3.803\n-2.382\n0.007\n0.005\n2792.0\n2477.0\n1.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occ.html#model-comparison",
    "href": "occ.html#model-comparison",
    "title": "Occupancy models",
    "section": "Model comparison",
    "text": "Model comparison\nPyMC also has handy tools for model comparison. I demonstrate these by fitting a model to the warbler data with a constant probability of detection.\n\nY_sum = Y.sum(axis=1)\n\nwith pm.Model(coords=coords) as warbler_constantp:\n\n    # occurrence process priors \n    Beta = pm.Normal(\"Beta\", mu=0, sigma=2, dims=\"beta_coefs\")\n    \n    # linear model\n    mu = pm.math.dot(X, Beta)\n    psi = pm.Deterministic(\"psi\", pm.math.invlogit(mu))\n\n    # detection process priors\n    p = pm.Uniform('p', 0, 1)\n\n    # likelihood\n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=J, observed=Y_sum)\n\npm.model_to_graphviz(warbler_constantp)\n\n\n\n\n\n\n\nFigure 9: Visual representaion of the warbler occupancy model with constant \\(p.\\)\n\n\n\n\n\n\nwith warbler_constantp:\n    warbler_constantp_idata = pm.sample(4000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Beta, p]\nSampling 4 chains for 1_000 tune and 4_000 draw iterations (4_000 + 16_000 draws total) took 5 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [20000/20000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nNext, I caclculate the leave-one-out (loo) cross-validation score for each model (Vehtari, Gelman, and Gabry 2017). This involves first computing the log likelihood for each model.\n\nwith warbler:\n    pm.compute_log_likelihood(warbler_idata)\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 00:00&lt;00:00]\n    \n    \n\n\n\nwarbler_loo = az.loo(warbler_idata)\n\nwarbler_loo\n\nComputed from 16000 posterior samples and 37 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -54.34     7.37\np_loo        6.13        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)       36   97.3%\n (0.5, 0.7]   (ok)          1    2.7%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nwith warbler_constantp:\n    pm.compute_log_likelihood(warbler_constantp_idata)\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 00:00&lt;00:00]\n    \n    \n\n\n\nwarbler_constantp_loo = az.loo(warbler_constantp_idata)\n\nwarbler_constantp_loo\n\nComputed from 16000 posterior samples and 37 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -39.30     5.11\np_loo        3.76        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)       37  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\nArviz has handy tools for comparing the results. First, I generate a tabular summary.\n\ndf_comp_loo = az.compare({r\"$p(visit,wheight)$\": warbler_idata, \n                          r\"$p(\\cdot)$\": warbler_constantp_idata})\ndf_comp_loo\n\n/Users/philtpatton/miniforge3/envs/mc/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/philtpatton/miniforge3/envs/mc/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\n$p(\\cdot)$\n0\n-39.297150\n3.764431\n0.000000\n1.000000e+00\n5.114314\n0.00000\nFalse\nlog\n\n\n$p(visit,wheight)$\n1\n-54.340158\n6.131376\n15.043009\n5.879741e-13\n7.372541\n4.20795\nFalse\nlog\n\n\n\n\n\n\n\nThis indicates that the \\(p(\\cdot)\\) model is favored over the \\(p(visit,wheight)\\) model.\nArviz also generates plots for these comparisons.\n\naz.plot_compare(df_comp_loo, insample_dev=False);\n\n/Users/philtpatton/miniforge3/envs/mc/lib/python3.11/site-packages/arviz/plots/backends/matplotlib/compareplot.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  scale = comp_df[\"scale\"][0]\n\n\n\n\n\n\n\n\nFigure 10: Comparison between the \\(p(visit,wheight)\\) and the \\(p(\\cdot)\\) models in terms of loo.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "surv.html",
    "href": "surv.html",
    "title": "Open capture-recapture",
    "section": "",
    "text": "In this notebook, I explore models for estimating survival using capture-recapture data in PyMC. These models include the Cormack-Jolly-Seber (CJS) and Jolly-Seber-Shwarz-Arnason (JSSA) frameworks. The primary difference between the two is that the JSSA model also tries to estimate the probability of entry into the population, which permits esimation of the superpopulation size.\nIn this notebook, I have drawn considerable inspiration from Austin Rochford’s notebook on capture-recapture in PyMC, the second chapter of my dissertation (a work in progress), and McCrea and Morgan (2014).\n\nCormack-Jolly-Seber\nFirst, I explore fitting the Cormack-Jolly-Seber (CJS) model in PyMC. The CJS framework does not model entrance into the population, just survival, simplifying the model structure. There are many methods for estimating parameters in the model, including state-space formulations that explicitly model the latent alive/dead state \\(z.\\) Following the theme of the previous notebooks, I instead marginalize this variable out of the model by using the so-called \\(M\\)-array. This is an array that contains the sufficient statistics for the CJS and JSSA models. For example, \\(m_{1,2}\\) is the number of individuals that were released on at \\(t=1\\) and were first recaptured on \\(t=2.\\)\n\nAn example of the M-array from a four year capture-recapture survey. The number recaptured, \\(m_{i,j}\\) refers to the number of individuals released at \\(i\\) who were first recaptured at time \\(j\\).\n\n\n\n\n\n\n\n\n\n\n\nNumber Released\n\nNumber recaptured\n\nNever recaptured\n\n\n\n\n\n\n1982\n1983\n1984\n\n\n\n1981\n\\(R_1\\)\n\\(m_{1,2}\\)\n\\(m_{1,3}\\)\n\\(m_{1,4}\\)\n\\(R_1-m_{1\\cdot}\\)\n\n\n1982\n\\(R_2\\)\n\n\\(m_{2,3}\\)\n\\(m_{2,3}\\)\n\\(R_2-m_{2\\cdot}\\)\n\n\n1983\n\\(R_3\\)\n\n\n\\(m_{3,4}\\)\n\\(R_3-m_{3\\cdot}\\)\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport arviz as az\nimport pymc as pm \nimport pytensor.tensor as pt\n\nfrom pymc.distributions.dist_math import factln\nfrom scipy.linalg import circulant\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['figure.facecolor'] = 'white'\n\ndef create_recapture_array(history):\n    \"\"\"Create the recapture array from a capture history.\"\"\"\n    _, occasion_count = history.shape\n    interval_count = occasion_count - 1\n\n    recapture_array = np.zeros((interval_count, interval_count), int)\n    for occasion in range(occasion_count - 1):\n\n        # which individuals, captured at t, were later recaptured?\n        captured_this_time = history[:, occasion] == 1\n        captured_later = (history[:, (occasion + 1):] &gt; 0).any(axis=1)\n        now_and_later = captured_this_time & captured_later\n        \n        # when were they next recaptured? \n        remaining_history = history[now_and_later, (occasion + 1):]\n        next_capture_occasion = (remaining_history.argmax(axis=1)) + occasion \n\n        # how many of them were there?\n        ind, count = np.unique(next_capture_occasion, return_counts=True)\n        recapture_array[occasion, ind] = count\n        \n    return recapture_array.astype(int)\n\ndef create_m_array(history):\n    '''Create the m-array from a capture history.'''\n\n    # leftmost column of the m-array\n    number_released = history.sum(axis=0)\n\n    # core of the m-array \n    recapture_array = create_recapture_array(history)\n    number_recaptured = recapture_array.sum(axis=1)\n\n    # no animals that were released on the last occasion are recaptured\n    number_recaptured = np.append(number_recaptured, 0)\n    never_recaptured = number_released - number_recaptured\n\n    # add a dummy row at the end to make everything stack \n    zeros = np.zeros(recapture_array.shape[1])\n    recapture_array = np.row_stack((recapture_array, zeros))\n\n    # stack the relevant values into the m-array \n    m_array = np.column_stack((number_released, recapture_array, never_recaptured))\n\n    return m_array.astype(int)\n\ndef fill_lower_diag_ones(x):\n    '''Fill the lower diagonal of a matrix with ones.'''\n    return pt.triu(x) + pt.tril(pt.ones_like(x), k=-1)\n\nAs an example, I use the cormorant data from McCrea and Morgan (2014), Table 4.6. These data come from an eleven year capture-recapture study between 1982 and 1993. These were breeding cormorants of unknown age. The data is summarized in the \\(M\\)-array below. The last column is the number that were never recapured. The number released can be calculated from the array.\n\ncormorant = np.array([\n       [ 10,   4,   2,   2,   0,   0,   0,   0,   0,   0,  12],\n       [  0,  42,  12,  16,   1,   0,   1,   1,   1,   0,  83],\n       [  0,   0,  85,  22,   5,   5,   2,   1,   0,   1,  53],\n       [  0,   0,   0, 139,  39,  10,  10,   4,   2,   0,  94],\n       [  0,   0,   0,   0, 175,  60,  22,   8,   4,   2, 199],\n       [  0,   0,   0,   0,   0, 159,  46,  16,   5,   2, 193],\n       [  0,   0,   0,   0,   0,   0, 191,  39,   4,   8, 171],\n       [  0,   0,   0,   0,   0,   0,   0, 188,  19,  23, 284],\n       [  0,   0,   0,   0,   0,   0,   0,   0, 101,  55, 274],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  84,  97]])\n\n\ninterval_count, T = cormorant.shape\n\nnumber_recaptured = cormorant[:,:-1]\nnever_recaputured = cormorant[:,-1]\nnumber_released = number_recaptured.sum(axis=1) + never_recaputured\n\nThis PyMC model will look different than the ones in previous notebooks, simply because it requires many tricks to get the probabilities in the correct format for the \\(m\\)-array, then modeling the \\(m\\)-array as a multinomial with the associated cell probabilities. These probabilities correspond to the situations in the \\(m\\)-array, such as the probability that an animal survived and was not recaptured until a later date. In this example, I model survival as time-varying, i.e., \\(\\phi(t).\\)\n\n# utility vectors for creating arrays and array indices\nintervals = np.arange(interval_count)\nrow_indices = np.reshape(intervals, (interval_count, 1))\ncol_indices = np.reshape(intervals, (1, interval_count))\n\n# matrix indicating the number of intervals between sampling occassions\nintervals_between = np.clip(col_indices - row_indices, 0, np.inf)\n\nwith pm.Model() as phit:\n\n    # priors for catchability and survival \n    p = pm.Uniform('p', 0, 1)\n    phi = pm.Uniform('phi', 0, 1, shape=interval_count)\n\n    # broadcast phi into a matrix \n    phi_mat = pt.ones_like(number_recaptured) * phi\n    phi_mat = fill_lower_diag_ones(phi_mat) # fill irrelevant values \n    \n    # probability of surviving between i and j in the m-array \n    p_alive = pt.cumprod(phi_mat, axis=1)\n    p_alive = pt.triu(p_alive) # select relevant (upper triangle) values\n\n    # probability of not being captured between i and j\n    p_not_cap = pt.triu((1 - p) ** intervals_between)\n\n    # probabilities associated with each cell in the m-array\n    nu = p_alive * p_not_cap * p\n\n    # probability for the animals that were never recaptured\n    chi = 1 - nu.sum(axis=1)\n\n    # combine the probabilities into a matrix\n    chi = pt.reshape(chi, (interval_count, 1))\n    marr_probs = pt.horizontal_stack(nu, chi)\n\n    # distribution of the m-array \n    marr = pm.Multinomial(\n        'M-array',\n        n=number_released,\n        p=marr_probs,\n        observed=cormorant\n    )\n\npm.model_to_graphviz(phit)\n\n\n\n\n\n\n\nFigure 1: Visual representation of the CJS model\n\n\n\n\n\n\nwith phit:\n    cjs_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [p, phi]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nmccrea_p = [0.51]\nmccrea_phi = [0.79, 0.56, 0.83, 0.86, 0.73, 0.70, 0.81, 0.64, 0.46, 0.95]\n\naz.plot_trace(\n    cjs_idata, \n    figsize=(10, 4),\n    lines=[(\"phi\", {}, [mccrea_phi]), (\"p\", {}, [mccrea_p])] \n);\n\n\n\n\n\n\n\nFigure 2: Traceplots for the cormorant CJS model with \\(p(\\cdot)\\phi(t)\\). MLEs from McCrea and Morgan (2014) shown by vertical and horizontal lines.\n\n\n\n\n\nThe model samples fairly quickly in this parameterization. The traceplots above include comparisons to the estimates from McCrea and Morgan (2014). While a bit messy, the plots show a high level of agreement between their estimates and the ones here. To clean things up a bit, I plot the estimates for \\(\\phi\\) over time, along with the 94% credible intervals\n\nfig, ax = plt.subplots(figsize=(6,4))\n\nt = np.arange(1983, 1993)\n\nphi_samps = az.extract(cjs_idata, var_names='phi').values.T\nphi_median = np.median(phi_samps, axis=0)\n\nax.plot(t, phi_median, linestyle='dotted', color='lightgray', linewidth=2)\nax.violinplot(phi_samps, t, showmedians=True, showextrema=False)\n\nax.set_ylim((0,1))\n\nax.set_ylabel(r'Apparent survival $\\phi$')\nax.set_title(r'Cormorant CJS')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 3: Violin plots of the posterior for apparent surival over time from the cormorant CJS. Horizontal lines represent the posterior median.\n\n\n\n\n\n\n\nJolly-Seber-Shwarz-Arnason (JSSA)\nThe second modeling framework I explore is the Jolly-Seber-Shwarz-Arnason (JSSA) model. This attempts to model entrants into the population, further permitting the estimation of the superpopulation size. As a demonstration, I use the classic European dipper data of Lebreton et al. (1992). I first convert the dataset into the \\(M\\)-array, since the data is in capture history format.\n\ndipper = np.loadtxt('dipper.csv', delimiter=',').astype(int)\ndipper[:5]\n\narray([[1, 1, 1, 1, 1, 1, 0],\n       [1, 1, 1, 1, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0]])\n\n\n\ndipper_m = create_m_array(dipper)\ndipper_m\n\narray([[22, 11,  2,  0,  0,  0,  0,  9],\n       [60,  0, 24,  1,  0,  0,  0, 35],\n       [78,  0,  0, 34,  2,  0,  0, 42],\n       [80,  0,  0,  0, 45,  1,  2, 32],\n       [88,  0,  0,  0,  0, 51,  0, 37],\n       [98,  0,  0,  0,  0,  0, 52, 46],\n       [93,  0,  0,  0,  0,  0,  0, 93]])\n\n\nThe JSSA model requires modeling the number of unmarked animals that were released during an occasion. We can calculate this using the \\(m\\)-array by subtracting the number of marked animals who were released from the total number of released animals.\n\nrecapture_array = create_recapture_array(dipper)\n\nnumber_released = dipper_m[:,0]\nnumber_marked_released = recapture_array.sum(axis=0)\n\n# shift number_released to get the years to align   \nnumber_unmarked_released = number_released[1:] - number_marked_released\n\n# add the number released on the first occasion \nnumber_unmarked_released = np.concatenate(\n    ([number_released[0]], number_unmarked_released)\n)\n\nnumber_unmarked_released\n\narray([22, 49, 52, 45, 41, 46, 39])\n\n\nSimilar to the CJS model, this model requires a number of tricks to vectorize the operations. Many pertain to the distribution of the unmarked individuals. Similar to occupancy notebook, I use a custom distribution to model the entrants into the population. Austin Rochford refers to this as an incomplete multinomial distribution.\n\nn, occasion_count = dipper.shape\ninterval_count = occasion_count - 1\n\n# generate indices for the m_array  \nintervals = np.arange(interval_count)\nrow_indices = np.reshape(intervals, (interval_count, 1))\ncol_indices = np.reshape(intervals, (1, interval_count))\n\n# matrix indicating the number of intervals between sampling occassions\nintervals_between = np.clip(col_indices - row_indices, 0, np.inf)\n\n# index for generating sequences like [[0], [0,1], [0,1,2]]\nalive_yet_unmarked_index = circulant(np.arange(occasion_count))\n\n\ndef logp(x, n, p):\n    \n    x_last = n - x.sum()\n    \n    # calculate thwe logp for the observations\n    res = factln(n) + pt.sum(x * pt.log(p) - factln(x)) \\\n            + x_last * pt.log(1 - p.sum()) - factln(x_last)\n    \n    # ensure that the good conditions are met.\n    good_conditions = pt.all(x &gt;= 0) & pt.all(x &lt;= n) & (pt.sum(x) &lt;= n) & \\\n                        (n &gt;= 0)\n    res = pm.math.switch(good_conditions, res, -np.inf)\n\n    return res\n\n\n# m-array for the CJS portion of the likelihood\ncjs_marr = dipper_m[:-1,1:]\ncjs_marr\n\narray([[11,  2,  0,  0,  0,  0,  9],\n       [ 0, 24,  1,  0,  0,  0, 35],\n       [ 0,  0, 34,  2,  0,  0, 42],\n       [ 0,  0,  0, 45,  1,  2, 32],\n       [ 0,  0,  0,  0, 51,  0, 37],\n       [ 0,  0,  0,  0,  0, 52, 46]])\n\n\nAside from the unmarked portion of the model, the JSSA model is essentially identical to the CJS model above. In this version, I also model survival as time-varying, holding other parameters constant \\(p(\\cdot)\\phi(t)b_0(\\cdot)\\)\n\n# JSSA produces this warning. it's unclear why since it samples well\nimport warnings\nwarnings.filterwarnings(\n    \"ignore\", \n    message=\"Failed to infer_shape from Op AdvancedSubtensor\"\n)\n\nwith pm.Model() as jssa:\n\n    ## Priors\n    \n    # catchability, survival, and pent\n    p = pm.Uniform('p', 0., 1.)\n    phi = pm.Uniform('phi', 0., 1., shape=interval_count)\n    b0 = pm.Uniform('b0', 0., 1.)\n    # beta = pm.Dirichlet('beta', np.ones(interval_count))\n    \n    # # only estimate first beta, others constant\n    b_other = (1 - b0) / (interval_count)\n    beta = pt.concatenate(\n        ([b0], pt.repeat(b_other, interval_count))\n    )\n\n    # improper flat prior for N\n    flat_dist = pm.Flat.dist()\n    total_captured = number_unmarked_released.sum()\n    N = pm.Truncated(\"N\", flat_dist, lower=total_captured)\n\n    ## Entry \n    \n    # add [1] to ensure the addition of the raw beta_0\n    p_alive_yet_unmarked = pt.concatenate(\n        ([1], pt.cumprod((1 - p) * phi))\n    )\n\n    # tril produces the [[0], [0,1], [0,1,2]] patterns for the recursion\n    psi = pt.tril(\n        beta * p_alive_yet_unmarked[alive_yet_unmarked_index]\n    ).sum(axis=1)\n\n    # distribution for the unmarked animals\n    unmarked = pm.CustomDist(\n        'Unmarked captures', \n        N, \n        psi * p, \n        logp=logp, \n        observed=number_unmarked_released\n    )\n\n    ## CJS\n    \n    # broadcast phi into a matrix \n    phi_mat = pt.ones_like(recapture_array) * phi\n    phi_mat = fill_lower_diag_ones(phi_mat) # fill irrelevant values \n    \n    # probability of surviving between i and j in the m-array \n    p_alive = pt.cumprod(phi_mat, axis=1)\n    p_alive = pt.triu(p_alive) # select relevant (upper triangle) values\n    \n    # p_not_cap: probability of not being captured between i and j\n    p_not_cap = pt.triu((1 - p) ** intervals_between)\n\n    # nu: probabilities associated with each cell in the m-array\n    nu = p_alive * p_not_cap * p\n\n    # probability for the animals that were never recaptured\n    chi = 1 - nu.sum(axis=1)\n\n    # combine the probabilities into a matrix\n    chi = pt.reshape(chi, (interval_count, 1))\n    marr_probs = pt.horizontal_stack(nu, chi)\n\n    # distribution of the m-array \n    marr = pm.Multinomial(\n        'M-array',\n        n=number_released[:-1], # last count irrelevant for CJS\n        p=marr_probs,\n        observed=cjs_marr\n    )\n\npm.model_to_graphviz(jssa)\n\n\n\n\n\n\n\nFigure 4: Visual representation of the JSSA model\n\n\n\n\n\n\nwith jssa:\n    jssa_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [p, phi, b0, N]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nphi_mle = [0.63, 0.46, 0.48, 0.62, 0.61, 0.58]\np_mle = [0.9]\nb0_mle = [0.079]\nN_mle = [310]\n\naz.plot_trace(\n    jssa_idata, \n    figsize=(10, 8),\n    lines=[(\"phi\", {}, phi_mle), (\"p\", {}, [p_mle]), (\"N\", {}, [N_mle]), (\"b0\", {}, [b0_mle])] \n);\n\n\n\n\n\n\n\nFigure 5: Traceplots for the dipper JSSA model. MLEs from the openCR package shown by vertical and horizontal lines.\n\n\n\n\n\nThe traceplots include the maximum likelihood estimates from the model, which I estimated usingthe openCR package in R. Again, there is high level of agreement between the two methods. I plot the survival estimates over time, and the posterior draws of \\(N\\), \\(p\\), and \\(b\\).\n\nfig, ax = plt.subplots(figsize=(6,4))\n\nt = np.arange(1981, 1987)\n\nphi_samps = az.extract(jssa_idata, var_names='phi').values.T\nphi_median = np.median(phi_samps, axis=0)\n\nax.plot(t, phi_median, linestyle='dotted', color='lightgray', linewidth=2)\nax.violinplot(phi_samps, t, showmedians=True, showextrema=False)\n\nax.set_ylim((0,1))\n\nax.set_ylabel(r'Apparent survival $\\phi$')\nax.set_title(r'Dipper JSSA')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 6: Violin plots of the posterior for apparent surival over time from the cormorant CJS. Horizontal lines represent the posterior median.\n\n\n\n\n\n\npost = jssa_idata.posterior\n\n# stack the draws for each chain, creating a (n_draws, n_species) array \np_samps = post.p.to_numpy().flatten()\nN_samps = post.N.to_numpy().flatten()\nb_samps = post.b0.to_numpy().flatten()\n\n# create the plot\nfig, (ax0, ax1) = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n\n# add the scatter for each species\nalph = 0.2\nax0.scatter(p_samps, N_samps, s=5, alpha=alph)\n\nax0.spines.right.set_visible(False)\nax0.spines.top.set_visible(False)\n\nax0.set_ylabel(r'$N$')\nax0.set_xlabel(r'$p$')\n\nax1.scatter(b_samps, N_samps, s=5, alpha=alph)\n\nax1.set_xlabel(r'$b_0$')\n\nfig.suptitle('Dipper JSSA posterior draws')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 7: Posterior draws of \\(N,\\) \\(b_0,\\) and \\(p\\) from the dipper JSSA model.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nLebreton, Jean-Dominique, Kenneth P Burnham, Jean Clobert, and David R Anderson. 1992. “Modeling Survival and Testing Biological Hypotheses Using Marked Animals: A Unified Approach with Case Studies.” Ecological Monographs 62 (1): 67–118.\n\n\nMcCrea, Rachel S, and Byron JT Morgan. 2014. Analysis of Capture-Recapture Data. CRC Press.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Open capture-recapture"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Philip T. Patton",
    "section": "",
    "text": "Phil is a PhD candidate in the Marine Mammal Research Program at the Hawaiʻi Institute of Marine Biology, and a NOAA QUEST Fellow with the Cetacean Research Program at the Pacific Islands Fisheries Science Center.\nFor his dissertation, he’s researching ways to improve stock assessments of non-migratory dolphins in Hawaiʻi. This includes automating photo-identification of these animals, understanding how these automated tools interact with capture-recapture models, and estimating demographic parameters using cutting edge methods in capture recapture.\nHe did his master’s with Krishna Pacifici at North Carolina State University, where he studied ways to improve estimates of species distribution, particularly when species interact and when the data contains sampling errors."
  },
  {
    "objectID": "dist.html",
    "href": "dist.html",
    "title": "Distance sampling",
    "section": "",
    "text": "In this notebook, I explore how to fit distance sampling models for estimating the size of a closed population. Similar to the occupancy and closed capture-recapture notebooks, I use parameter-expanded data-augmentation (PX-DA) and the zero-inflated binomial model in this notebook.\nThe idea with distance sampling, also known as line-transect sampling, is that a surveyer traverses a transect, typically in a boat or a plane. As they survey, they note when they detect an individual, or a group, from the species of interest, and further note the distance from the transect to the animal. Further, they note the angle to the animal(s), such that they can calculate the perpendicular distance from the animal to the transect. We assume that probability of detecting an animal \\(p\\) decreases monotonically as the distance from the transect grows, e.g., \\(p=\\exp(-x^2/\\sigma^2),\\) where \\(x\\) is the distance and \\(\\sigma\\) is a scale parameter to be estimated. These simple assumptions permit the estimation of the population size \\(N\\) as well as density \\(D.\\)\nFollowing Hooten and Hefley (2019), Chapter 24 and Royle and Dorazio (2008), Chapter 7, I use the impala data from Burnham, Anderson, and Laake (1980), who credits P. Hemingway with the dataset. In this dataset, 73 impalas were observed along a 60km transect. The distance values below are the perpendicular distances, in meters, from the transect.\n\nimport pymc as pm\nimport pytensor.tensor as pt\nimport matplotlib.pyplot as plt\nimport arviz as az\nimport numpy as np\n\n# plotting defaults\nplt.style.use('fivethirtyeight')\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['figure.facecolor'] = 'white'\n\n# hyper parameters\nM = 500\nU_X = 400\nU_SIGMA = 400\n\n# burnham impala dataset with distances in m\nx_observed = np.array(\n    [71.933980, 26.047227, 58.474341, 92.349221, 163.830409, 84.523652\n    ,163.830409, 157.330098, 22.267696, 72.105330, 86.986979, 50.795047\n    ,0.000000, 73.135370,  0.000000, 128.557522, 163.830409,  71.845104\n    ,30.467336, 71.073909, 150.960702, 68.829172, 90.000000, 64.983827\n    ,165.690874, 38.008322, 378.207430, 78.146226, 42.127052, 0.000000\n    ,400.000000, 175.386612, 30.467336, 35.069692, 86.036465, 31.686029\n    ,200.000000, 271.892336, 26.047227, 76.604444, 41.042417, 200.000000\n    ,86.036465, 0.000000, 93.969262, 55.127471, 10.458689, 84.523652\n    ,0.000000, 77.645714, 0.000000, 96.418141, 0.000000, 64.278761\n    ,187.938524, 0.000000, 160.696902, 150.453756, 63.603607, 193.185165\n    ,106.066017, 114.906666, 143.394109, 128.557522, 245.745613, 123.127252\n    ,123.127252, 153.208889, 143.394109, 34.202014, 96.418141, 259.807621\n    ,8.715574]\n)\n\n# plot the distances \nfig, ax = plt.subplots(figsize=(4,4))\n\nax.hist(x_observed, edgecolor='white')\n\nax.set_title('Hemingway Impala Data')\nax.set_ylabel('Number of detections')\nax.set_xlabel('Distance (m)')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 1: Histogram of the number of detected impalas at varying distances.\n\n\n\n\n\nAgain, we treat this as a zero-inflated binomial model using PX-DA. The trick for doing so is to create a binary vector of length \\(M\\), \\(y,\\) that represents whether the individual was detected during the study. Then, combine the indicator with the distance vector \\(x\\) to create a the full dataset \\((x,y).\\)\n\nn = len(x_observed)\nunobserved_count = M - n\nzeros = np.zeros(unobserved_count)\n\ny = np.ones(n)\ny_augmented = np.concatenate((y, zeros))\n\nThe issue is that \\(x\\) is unobserved for the undetected individuals. To work around this, we put a uniform prior on the unobserved \\(x,\\) i.e., \\(x \\sim \\text{Uniform}(0, U_x).\\) With this “complete” \\(x,\\) we can construct the detection function \\(p\\) for the unobserved individuals.\n\nwith pm.Model() as distance:\n    \n    psi = pm.Uniform('psi', 0, 1)\n    sigma = pm.Uniform('sigma', 0, U_SIGMA)\n    \n    x_unobserved = pm.Uniform('x_unobserved', 0, U_X, shape=unobserved_count)\n    x_complete = pt.concatenate((x_observed, x_unobserved))\n\n    p = pm.Deterministic('p', pm.math.exp(- x_complete ** 2 / sigma ** 2))\n    \n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=1, observed=y_augmented)\n\npm.model_to_graphviz(distance)\n\n\n\n\n\n\n\nFigure 2: Visual representation of the distance sampling model.\n\n\n\n\n\n\nwith distance:\n    distance_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, sigma, x_unobserved]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_trace(\n    distance_idata, \n    figsize=(10,4),\n    var_names=['psi', 'sigma']\n);\n\n\n\n\n\n\n\nFigure 3: Traceplots for the distance sampling model.\n\n\n\n\n\nThis model samples slower than the models in the other notebooks, presumably because of the unobserved \\(x.\\) As in the closed capture-recapture notebook, we will have to simulate the posterior for \\(N\\) using the posterior distribution of \\(\\psi\\) and \\(M.\\)\n\n# RNG = np.random.default_rng()\n\n# this does not make a copy of the posterior\n# post = distance_idata.posterior\n\n# # simulate draws of N using the posterior of psi \n# N_samples = RNG.binomial(M, post.psi)\n# N_samples = N_samples.flatten()\n# N_hat = N_samples.mean()\n\nRNG = np.random.default_rng()\n\nposterior = az.extract(distance_idata)\npsi_samples = posterior.psi.to_numpy()\np_samples = posterior.p.to_numpy()\n\nnot_p = (1 - p_samples[n:])\np_included = (not_p * psi_samples) / (not_p * psi_samples + (1 - psi_samples))\nn_undetected = RNG.binomial(1, p_included).sum(axis=0)\nN_samples = n + n_undetected\n\n\nsigma_samples = posterior.sigma.to_numpy()\n\n# plot the results\nfig, (ax0, ax1) = plt.subplots(1, 2, sharey=True, figsize=(8,4))\n\n# histograms of the posteriors\nax0.hist(N_samples, edgecolor='white', bins=30)\nax1.hist(sigma_samples, edgecolor='white', bins=30)\n\n# show the abundance dist in terms of M\n# ax0.set_xlim((100, M))\n\n# axes labels \nax0.set_xlabel('Abundance $N$')\nax0.set_ylabel('Number of samples')\nax1.set_xlabel('Detection range $\\sigma$')\n\n# add the point estimates\nN_hat = N_samples.mean()\nsigma_hat = sigma_samples.mean()\nax0.text(200, 350, f'$\\hat{{N}}$={N_hat:.1f}', ha='left', va='center')\nax1.text(205, 350, f'$\\hat{{\\sigma}}$={sigma_hat:.1f}', ha='left', va='center')\n\n# the results from royle and dorazio (2008) for comparison\nN_hat_royle = 179.9\nsigma_hat_royle = 187\n\nax0.axvline(N_hat_royle, linestyle='--', linewidth=3, color='C1')\nax1.axvline(sigma_hat_royle, linestyle='--', linewidth=3, color='C1')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 4: Posterior distributions for \\(N\\) and \\(\\sigma.\\) Estimates from Royle and Dorazio (2008) are shown with vertical lines.\n\n\n\n\n\nThe model shows a high level of agreement with Royle and Dorazio (2008), Chapter 7, although note that they reported \\(\\sigma\\) in terms of 100m units. It is also possible to plot the posterior distribution of the detection function.\n\nxx = np.arange(400)\n\ndef det_func(x, s):\n    return np.exp(- (x ** 2) / (s ** 2))\n\np_samps = np.array([det_func(xx, s) for s in sigma_samples])\n\np_mean = p_samps.mean(axis=0)\np_low = np.quantile(p_samps, 0.02, axis=0)\np_high = np.quantile(p_samps, 0.98, axis=0)\n\nfig, ax = plt.subplots(figsize=(5,4))\n\nax.plot(xx, p_mean, '-')\nax.fill_between(xx, p_low, p_high, alpha=0.2)\n\nax.set_title('Detection function')\nax.set_ylabel(r'$p$')\nax.set_xlabel(r'Distance (m)')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 5: Posterior distribution for the detection function. The line represents the posterior mean while the shaded area is the 96% interval.\n\n\n\n\n\n\n\n\n\nReferences\n\nBurnham, Kenneth P, David R Anderson, and Jeffrey L Laake. 1980. “Estimation of Density from Line Transect Sampling of Biological Populations.” Wildlife Monographs, no. 72: 3–202.\n\n\nHooten, Mevin B, and Trevor Hefley. 2019. Bringing Bayesian Models to Life. CRC Press.\n\n\nRoyle, J Andrew, and Robert M Dorazio. 2008. Hierarchical Modeling and Inference in Ecology: The Analysis of Data from Populations, Metapopulations and Communities. Elsevier.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Distance sampling"
    ]
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "Notebooks",
    "section": "",
    "text": "Please find here any notebooks that I may have thought would be of general interest. For now, these mainly consist of my attempts to port standard ecological models to PyMC, a Python library for doing Bayesian analysis.\n\nPyMC\nThere are many valuable tools for fitting hierarchical models in ecology. These tools are typically R libraries, such as unmarked, or programs called from R, such as JAGS or Stan. There are relatively fewer examples of how to fit these models in Python. While most ecologists, and arguably statisticians, use R, there are some benefits to using Python generally. For example, despite ecology being a lucrative industry, some of us might have to pivot to another field where Python may be more common. Besides, Python is widely used for machine learning, which is increasingly applied in ecology.\nIn the PyMC notebooks, I try to demonstrate how to use PyMC to train the most common hierarchcial models in ecology. For this, I have drawn considerable inspiration from Royle and Dorazio (2008), Kéry and Schaub (2011), McCrea and Morgan (2014), and Hooten and Hefley (2019), oftentimes simply porting their code, ideas, and analyses. In doing so, I hope to demonstrate PyMC’s core features, and highlight its strengths and weakenesses. The PyMC notebooks are somewhat sequential, with earlier notebooks explaining more basic features.\n\n\n\n\n\nReferences\n\nHooten, Mevin B, and Trevor Hefley. 2019. Bringing Bayesian Models to Life. CRC Press.\n\n\nKéry, Marc, and Michael Schaub. 2011. Bayesian Population Analysis Using WinBUGS: A Hierarchical Perspective. Academic Press.\n\n\nMcCrea, Rachel S, and Byron JT Morgan. 2014. Analysis of Capture-Recapture Data. CRC Press.\n\n\nRoyle, J Andrew, and Robert M Dorazio. 2008. Hierarchical Modeling and Inference in Ecology: The Analysis of Data from Populations, Metapopulations and Communities. Elsevier.",
    "crumbs": [
      "Notebooks"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Philip T. Patton",
    "section": "",
    "text": "Phil is a PhD candidate in the Marine Mammal Research Program at the Hawaiʻi Institute of Marine Biology, and a NOAA QUEST Fellow with the Cetacean Research Program at the Pacific Islands Fisheries Science Center.\nFor his dissertation, he’s researching ways to improve stock assessments of non-migratory dolphins in Hawaiʻi. This includes automating photo-identification of these animals, understanding how these automated tools interact with capture-recapture models, and estimating demographic parameters using cutting edge methods in capture recapture.\nHe did his master’s with Krishna Pacifici at North Carolina State University, where he studied ways to improve estimates of species distribution, particularly when species interact and when the data contains sampling errors."
  },
  {
    "objectID": "closed_cmr.html",
    "href": "closed_cmr.html",
    "title": "Closed capture-recapture",
    "section": "",
    "text": "In this notebook, I explore fitting closed population capture-recapture models in PyMC. Capture-recapture, at least the Lincoln-Peterson estimator, has been around for almost 100 years. Since then, countless varieties of capture-recapture models have been developed for closed populations (Otis et al. 1978).\nThe basic steps in capture-recapture are: capture several individuals–e.g., via trapping–from the population of interest, mark these animals, then release them. We repeat this process several times, each time noting when we recapture individuals.\n\n\n\nTable 1: Example capture history, where \\(t\\) is the sampling occasion and 1 indicates capture\n\n\n\n\n\nIndividual\n\\(t_1\\)\n\\(t_2\\)\n\\(t_3\\)\n\\(t_4\\)\n\n\n\n\n001\n1\n1\n0\n1\n\n\n002\n0\n1\n1\n1\n\n\n003\n0\n0\n1\n1\n\n\n\n\n\n\nThis produces a capture history for each individual, which allows us to estimate the probability of capture and the number of individuals in the population \\(N\\).\n\nModel \\(M_0\\)\n\n# libraries \nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport arviz as az\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom pymc.distributions.dist_math import binomln, logpow\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['figure.facecolor'] = 'white'\n# pal = sns.color_palette(\"Set2\")\n# sns.set_palette(pal)\n\n# hyperparameters \nSEED = 808\nRNG = np.random.default_rng(SEED)\nM = 1500\n\nI explore fitting the simplest closed capture-recapture model, Model \\(M_0,\\) through parameter-expanded data-augmentation (PX-DA, Royle and Dorazio 2008). The idea with PX-DA is to augment the capture histories with \\(M-n\\) all zero capture-histories, where \\(M\\) is a hyperparameter that should be much greater than the true population size \\(N,\\) and \\(n\\) is the total number of individuals that were captured during the study. This allows us to treat the data as a zero-inflated binomial distribution (see below).\n\ndef augment_history(history):\n    '''Augment a capture history with all-zero histories.'''\n    \n    animals_captured, T = history.shape\n\n    # create M - n all zero histories\n    zero_history_count = M - animals_captured\n    zero_history = np.zeros((zero_history_count, T))\n\n    # tack those on to the capture history\n    augmented = np.row_stack((history, zero_history))\n\n    return augmented \n\nTo demonstrate this approach, I use the salamander dataset from Bailey, Simons, and Pollock (2004), as demonstrated in Hooten and Hefley (2019), Chapter 24. These data were collected on two salamander species, the red-cheeked salamander (Plethodon jordani) and the pygmy salamander (Desmognathus wrighti), in Great Smoky Mountains National Park. The salamanders were counted in 15m by 15m square plots. In this case, we augment the history by setting \\(M=1500\\) (see above). There were \\(n=92\\) individual red-cheeked and \\(n=132\\) pygmy salamanders captured during the course of the survey.\n\ndef get_histories():\n    '''Read, augment, and recombine the salamander histories.'''\n    \n    # read in salamander data \n    sal_data = pd.read_csv('sal_data.csv')\n    \n    # labels for capture history columns \n    col_labs = [f'y{t}' for t in range(1, 5)]\n\n    # subset each dataset before augmenting \n    is_pyg = sal_data.spp == 1\n    is_red = sal_data.spp == 0\n\n    pyg = sal_data.loc[is_pyg, col_labs].to_numpy()\n    red = sal_data.loc[is_red, col_labs].to_numpy()\n\n    # # augment each set separately since they differ in length\n    # pyg_augmented = augment_history(pyg)\n    # red_augmented = augment_history(red)\n\n    # # recombine into one history \n    # history = np.concatenate((pyg_augmented, red_augmented))\n\n    return {'pyg': pyg, 'red': red}\n\ndef augment_histories(histories):\n\n    pyg_augmented = augment_history(histories['pyg'])\n    red_augmented = augment_history(histories['red'])\n\n    # recombine into one history \n    history = np.concatenate((pyg_augmented, red_augmented))\n\n    return history\n\nhistories = get_histories()\n\nn_red, T = histories['red'].shape\nn_pyg, T = histories['pyg'].shape\n\n# # summarize into binomial data\nhistory_augmented = augment_histories(histories)\nhistory_summarized = history_augmented.sum(axis=1)\n\nFor this model, I use the pm.ZeroInflatedBinomial class, just as I did in the occupancy notebook. That said, the parameters here are different. First, \\(p\\) represents the probability of capturing a given individual during the survey. Second, \\(\\psi\\) represents a mysterious entity known as the inclusion probability. That is, the probability that an individual from the hypothetical superpopulation \\(M\\) is included in the population of interest \\(N.\\) Then, we can estimate the population size as \\(\\hat{N}=M\\hat{\\psi},\\) or generate posterior draws of \\(N,\\) e.g., \\(N^{(s)} \\sim \\text{Bin}(M,\\psi^{(s)})\\)\nIn this example, I combine the two species into one pm.Model object, making use of coords. That said, the parameters for each species are treated as independent. In other words, this is a “no-pooling” model.\n\n# index for each species\nspecies_idx = np.repeat([0, 1], M)\n\n# coordinates identifying parameter each species  \ncoords = {'species': ['pygmy', 'red_cheeked']}\n\nwith pm.Model(coords=coords) as M0:\n\n    # priors for the capture and inclusion probabilities\n    psi = pm.Uniform('psi', 0, 1, dims='species')\n    p = pm.Uniform('p', 0, 1, dims='species')\n\n    # likelihood for the summarized data\n    pm.ZeroInflatedBinomial(\n        'history', \n        p=p[species_idx], \n        psi=psi[species_idx], \n        n=T,\n        observed=history_summarized\n    )\n    \npm.model_to_graphviz(M0)\n\n\n\n\n\n\n\nFigure 1: Visual representation of model \\(M_0.\\) MarginalMixture refers to the zero-inflated binomial distribution.\n\n\n\n\n\n\nwith M0:\n    M0_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, p]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 18 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:17&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_trace(M0_idata, figsize=(8,4));\n\n\n\n\n\n\n\nFigure 2: Traceplots for the salamander \\(M_0\\) model. The red-cheeked salamander is in blue while the pygmy salamander is in red.\n\n\n\n\n\nFor faster sampling, it’s better to separate the two species into two separate models. On my machine, the individual species models finish sampling in 2-3 seconds, compared to 15-20 seconds for the two species model. That said, the two species model is somewhat more convenient.\nOf course, the trace plots lack our true parameter of interest: the population size \\(N.\\) We can simulate the posterior of \\(N\\) as a derived quantity, using the posterior distribution of \\(\\psi\\) and \\(p.\\)\n\n# az.extract flattens the chains\nposterior = az.extract(M0_idata)\npsi_samps = posterior.psi.values\np_samps = posterior.p.values\n\n# conditional probability that the animal is in the sample \nnot_p = (1 - p_samps)\np_included = (psi_samps * (not_p) ** T) / (psi_samps * (not_p) ** T + (1 - psi_samps))\n\n# simulate the number of undetected animals in each population\nnumber_undetected_pyg = RNG.binomial(M - n_pyg, p_included[0])\nnumber_undetected_red = RNG.binomial(M - n_red, p_included[1])\n\n# simulate N\nN_pyg = n_pyg + number_undetected_pyg\nN_red = n_red + number_undetected_red\n\nBelow I plotted the posterior distributions of \\(N\\) for both species, adding the estimates from Hooten and Hefley (2019), Chapter 24. Although note that they used a different prior for \\(\\psi.\\)\n\nN_hooten = [229.6, 450.9]\nfig, ax = plt.subplots(figsize=(6,4))\nax.hist(N_pyg, color='C0', edgecolor='white', alpha=0.9, bins=30, label='Pygmy')\nax.hist(N_red, color='C1', edgecolor='white', alpha=0.9, bins=30, label='Red-cheeked')\nax.axvline(N_hooten[0], linestyle='--', color='black', linewidth=2)\nax.axvline(N_hooten[1], linestyle='--', color='black', linewidth=2)\nax.set_title('Posterior distributions of $N$')\nax.set_ylabel('Number of samples')\nax.legend()\nplt.show()\n\n\n\n\n\n\n\nFigure 3: Posterior distributions of \\(N\\) from the \\(M_0\\) model. Estimates from Hooten and Hefley (2019) are shown by the vertical lines’\n\n\n\n\n\nWe might expect estimates of capture probability \\(p\\) and the abundance \\(N\\) to be somewhat correlated. We can explore this relationship visually by plotting the posterior draws. For a more custom look to the plots, I plot the draws using matplotlib.\n\n# create the plot\nfig, ax = plt.subplots(1, 1, figsize=(4, 4))\n\n# add the scatter for each species\nlabs = ['Pygmy', 'Red-backed']\nax.scatter(p_samps[0], N_pyg, s=10, alpha=0.2, label=labs[0])\nax.scatter(p_samps[1], N_red, s=10, alpha=0.2, label=labs[1])\n\n# this removes the opacity for the dots in the legend\nleg = ax.legend()\nfor lh in leg.legend_handles: \n    lh.set(sizes=[25], alpha=[1])\n\n# update aesthetics \nax.spines.right.set_visible(False)\nax.spines.top.set_visible(False)\n\nax.set_ylabel(r'$N$')\nax.set_xlabel(r'$p$')\nax.set_title('Posterior draws')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 4: Posterior draws of \\(N\\) and \\(p\\) for both species of salamander.\n\n\n\n\n\n\n\nModel \\(M_b\\)\nNext, I fit model \\(M_b,\\) which accounts for the possibility that the capture probability changes after the animal is first caught. This could be from trap happiness, whereby animals are more likely to be trapped after their first time. Conversely, this could be from subsequent trap avoidance.\nMirroring (Royle and Dorazio 2008, chap. 5), I fit this model to the Microtus dataset reported in (Williams, Nichols, and Conroy 2002, 525). This version of the dataset includes encounter histories of \\(n=56\\) adult males that were captured on \\(T=5\\) consecutive days.\n\n# read in the microtus data\nmicrotus = np.loadtxt('microtus.data.txt').astype(int)\n\n# the last column is not relevant\nmicro_hist = microtus[:,:-1]\nn, T = micro_hist.shape\n\n# augment with all zero histories\nM = 100\nmicro_augmented = augment_history(micro_hist)\n\n# note the occasion when each individual was first seen\nfirst_seen = (micro_hist != 0).argmax(axis=1)\n\n# create the covariate for the behavior effect\nbehavior_effect = np.zeros((M, T))\nfor i, f in enumerate(first_seen):\n    behavior_effect[i, (f + 1):] = 1\n\n# covariate matrix\nx_int = np.ones((M, T))\nX = np.stack((x_int, behavior_effect), axis=2)\n\nI use the same custom distribution as the occupancy notebook, the zero-inflated model, except the zero-inflation happens at the row-level.\n\ndef logp(value, n, p, psi):\n    \n    binom = binomln(n, value) + logpow(p, value) + logpow(1 - p, n - value)\n    bin_sum = pm.math.sum(binom, axis=1)\n    bin_exp = pm.math.exp(bin_sum)\n\n    res = pm.math.switch(\n        value.sum(axis=1) &gt; 0,\n        bin_exp * psi,\n        bin_exp * psi + (1 - psi)\n    )\n    \n    return pm.math.log(res)\n\ncoords = {'alpha_coeffs': ['Intercept', 'B_Response']}\nwith pm.Model(coords=coords) as mb:\n\n    # priors for the capture and inclusion probabilities\n    psi = pm.Uniform('psi', 0, 1)\n    Alpha = pm.Normal('Alpha', 0, 2, dims='alpha_coeffs')\n\n    nu = pm.math.dot(X, Alpha)\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=micro_augmented\n    )\n    \npm.model_to_graphviz(mb)\n\n\n\n\n\n\n\nFigure 5: Visual representation of model \\(M_b.\\)\n\n\n\n\n\n\nwith mb:\n    mb_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, Alpha]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(mb_idata, var_names=['Alpha', 'psi'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAlpha[Intercept]\n0.111\n0.240\n-0.363\n0.527\n0.005\n0.004\n1955.0\n1703.0\n1.0\n\n\nAlpha[B_Response]\n0.621\n0.283\n0.043\n1.129\n0.006\n0.005\n1962.0\n1671.0\n1.0\n\n\npsi\n0.572\n0.052\n0.475\n0.671\n0.001\n0.001\n2309.0\n2088.0\n1.0\n\n\n\n\n\n\n\n\naz.plot_forest(mb_idata, var_names=['Alpha'], combined=True, ess=True, figsize=(6,2));\n\n\n\n\n\n\n\nFigure 6: Forest plot showing the catchability parameters from model \\(M_b.\\)\n\n\n\n\n\nThe forest plot indicates that there is some evidence of a weak, positive behavioral response. Although note that the 94% credible intervals between the baseline capture rate and the behavioral effect overlap considerably.\n\n# simulate draws of N \npsi_samps = az.extract(mb_idata).psi.values\np_samps = az.extract(mb_idata).p.values[:n]\n\nnot_p = (1 - p_samps)\nbin_prod = not_p.prod(axis=1)\np_included = (psi_samps * bin_prod) / (psi_samps * bin_prod + (1 - psi_samps))\n\nnumber_undetected = RNG.binomial(1, p_included).sum(axis=0)\nN_samples = n + number_undetected\n\n# use a bar chart since the posterior is bunched up \nN_values, N_counts = np.unique(N_samples, return_counts=True)\n\n# create the plot\nfig, ax = plt.subplots(figsize=(4, 4))\n\nax.bar(N_values, N_counts)\n\nax.annotate(\n    'Number\\ndetected $n$', \n    ha='left',\n    xy=(N_values[0], N_counts[0]), \n    color='black',\n    xytext=(n+1, 1600), \n    arrowprops=dict(arrowstyle=\"-&gt;\", color='black', linewidth=1,\n                    connectionstyle=\"angle3,angleA=90,angleB=0\")\n)\n\nax.set_ylabel('Number of samples')\nax.set_title('Posterior of $N$')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 7: Posterior distribution of \\(N\\) from model \\(M_b.\\) The number voles that were detected \\(n\\) is shown by the vertical red line.\n\n\n\n\n\nMost of the posterior density of \\(N\\) is at \\(n,\\) the number of animals detected. The discovery curve hints at why this may be the case. It seems that all the voles in the population may have been captured by the end of the study.\n\n# how many voles have been seen?\ntotal_seen = micro_hist.sum(axis=0).cumsum()\ntotal_seen = np.insert(total_seen, 0, 0)\n\n# how many new voles have been seen?\nfirst_seen = (micro_hist != 0).argmax(axis=1)\nnewbies = [sum(first_seen == t) for t in range(T)]\ntotal_newbies = np.cumsum(newbies)\ntotal_newbies = np.insert(total_newbies, 0, 0)\n\nfig, ax = plt.subplots(figsize=(5, 3.5))\nax.plot(total_seen, total_newbies)\nax.fill_between(total_seen, total_newbies, alpha=0.2)\nax.set_title('Discovery curve')\nax.set_xlabel('Total voles captured')\nax.set_ylabel('Unique voles captured')\nplt.show()\n\n\n\n\n\n\n\nFigure 8: Discovery curve for the Microtus study.\n\n\n\n\n\nWe can also look at the behavioral effect by visualizing the posterior distributions of \\(p.\\) As we can see, the voles who have been captured before are more likely to be captured again.\n\np_samples = az.extract(mb_idata).p.values.reshape(500, 4000)\nb_cov = X[:,:,1].flatten()\n\nzero_p = p_samples[b_cov==0,].flatten()\none_p = p_samples[b_cov==1,].flatten() \n\nfig, ax = plt.subplots(figsize=(5, 3.5))\naz.plot_dist(zero_p, ax=ax, label='First detection', color='C0')\naz.plot_dist(one_p, ax=ax, label='Seen before', color='C1')\nax.set_title('Posterior distributions of $p$')\nax.set_xlim((0,1))\nax.set_yticks([])\nax.legend()\nplt.show()\n\n\n\n\n\n\n\nFigure 9: Posterior distributions for the probability of detection given the behavioral effect.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nBailey, Larissa L, Theodore R Simons, and Kenneth H Pollock. 2004. “Estimating Detection Probability Parameters for Plethodon Salamanders Using the Robust Capture-Recapture Design.” The Journal of Wildlife Management 68 (1): 1–13.\n\n\nHooten, Mevin B, and Trevor Hefley. 2019. Bringing Bayesian Models to Life. CRC Press.\n\n\nOtis, David L, Kenneth P Burnham, Gary C White, and David R Anderson. 1978. “Statistical Inference from Capture Data on Closed Animal Populations.” Wildlife Monographs, no. 62: 3–135.\n\n\nRoyle, J Andrew, and Robert M Dorazio. 2008. Hierarchical Modeling and Inference in Ecology: The Analysis of Data from Populations, Metapopulations and Communities. Elsevier.\n\n\nWilliams, Byron K, James D Nichols, and Michael J Conroy. 2002. Analysis and Management of Animal Populations. Academic press.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Closed capture-recapture"
    ]
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Philip T. Patton",
    "section": "",
    "text": "Ph.D., Marine Biology, Hawaiʻi Institute of Marine Biology, 2025 (anticipated)\nM.S., Fisheries, Wildlife, and Conservation Biology, North Carolina State University, 2016\nB.S., Conservation Biology, SUNY College of Environmental Science and Forestry, 2013"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Philip T. Patton",
    "section": "",
    "text": "Ph.D., Marine Biology, Hawaiʻi Institute of Marine Biology, 2025 (anticipated)\nM.S., Fisheries, Wildlife, and Conservation Biology, North Carolina State University, 2016\nB.S., Conservation Biology, SUNY College of Environmental Science and Forestry, 2013"
  },
  {
    "objectID": "cv.html#research-experience",
    "href": "cv.html#research-experience",
    "title": "Philip T. Patton",
    "section": "Research Experience",
    "text": "Research Experience\n\nNOAA QUEST Fellow, Pacific Islands Fisheries Science Center, NOAA Fisheries, 2021 - Present\nGraduate Research Assistant, Hawaiʻi Institute of Marine Biology, University of Hawaiʻi at Mānoa, 2021 - Present\nGraduate Research Assistant, Quantitative Ecology & Resource Management, University of Washington, 2016 - 2017\nGraduate Research Assistant, Applied Ecology, North Carolina State University, 2014 - 2016"
  },
  {
    "objectID": "cv.html#professional-experience",
    "href": "cv.html#professional-experience",
    "title": "Philip T. Patton",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nData Analyst, Health Services, Deschutes County, 2020 - 2021\nData Analyst, Supply Chain AI & Machine Learning, Starbucks Coffee Company, 2019\nQuantitative Analyst, Seattle City Light, City of Seattle, 2017 - 2019"
  },
  {
    "objectID": "cv.html#grants-awards-and-fellowships",
    "href": "cv.html#grants-awards-and-fellowships",
    "title": "Philip T. Patton",
    "section": "Grants, Awards, and Fellowships",
    "text": "Grants, Awards, and Fellowships\n\nPeter Castro HIMB Graduate Student Support Fund - Travel, Hawaiʻi Institute of Marine Biology, 2023, $500\nLinda and Jim Collister Scholarship, Hawaiʻi Institute of Marine Biology, 2023, $1,000\nQuantitative Ecology and Socioeconomic Training Fellowship (QUEST), NOAA Fisheries, 2021 to present, $180,000\nAchievement Scholarship, University of Hawaiʻi at Mānoa, 2023, $500\nColonel Willys E. & Sandina L. Lord Endowed Scholarship, Hawaiʻi Institute of Marine Biology, 2022, $2,000\nStudent Travel Award, University of Washington, 2017, $500\nStudent and Postdoc Travel Award, University of Washington, 2017, $750\nTravel Award, University of Washington, 2017, $500\nGlobal Change Fellowship, USGS, 2015 to 2016, $12,000"
  },
  {
    "objectID": "cv.html#papers",
    "href": "cv.html#papers",
    "title": "Philip T. Patton",
    "section": "Papers",
    "text": "Papers\n\nPatton, P.T., Pacifici, K., Allen, J.B., Ashe, E., Athayde, A., Baird, R.W., Basran, C., Cabrera, E., Calambokidis, J., Cardoso, J., Carroll, E.L., Cesario, A., Cheeseman, T., Cheney, B.J., Corsi, E., Currie, J., Durban, J.W., Falcone, E.A., Fearnbach, H., Flynn, K., Franklin, T., Franklin, W., Vernazzani, B.G., Genov, T., Hill, M., Johnston, D.R., Keene, E.L., Mahaffy, S.D., McGuire, T.L., McPherson, L., Meyer, C., Michaud, R., Miliou, A., Oleson, E.M., Orbach, D.N., Pearson, H.C., Rasmussen, M.H., Rayment, W.J., Rinaldi, C., Rinaldi, R., Siciliano, S., Stack, S., Tintore, B., Torres, L.G., Towers, J.R., Trotter, C., Moore, R.T., Weir, C.R., Wellard, R., Wells, R., Yano, K.M., Zaeschmar, J.R. & Bejder, L. (TBD) Evaluating trade–offs between automation and bias in population assessments relying on photo-identification. (TBD) Evaluating trade-offs between automation and bias in population assessments relying on photo-identification. In prep\nPatton, P.T. Pacifici, K., Miller, D.A.W., & Collazo, J. (TBD) Partial pooling of data among species improves performance of occupancy models subject to two types of sampling error. In prep\nPatton, P.T. , Cheeseman, T., Abe, K., Yamaguchi, T., Reade, W., Southerland, K., Howard, A., Oleson, E.M., Allen, J.B., Ashe, E., Athayde, A., Baird, R.W., Basran, C., Cabrera, E., Calambokidis, J., Cardoso, J., Carroll, E.L., Cesario, A., Cheney, B.J., Corsi, E., Currie, J., Durban, J.W., Falcone, E.A., Fearnbach, H., Flynn, K., Franklin, T., Franklin, W., Vernazzani, B.G., Genov, T., Hill, M., Johnston, D.R., Keene, E.L., Mahaffy, S.D., McGuire, T.L., McPherson, L., Meyer, C., Michaud, R., Miliou, A., Orbach, D.N., Pearson, H.C., Rasmussen, M.H., Rayment, W.J., Rinaldi, C., Rinaldi, R., Siciliano, S., Stack, S., Tintore, B., Torres, L.G., Towers, J.R., Trotter, C., Moore, R.T., Weir, C.R., Wellard, R., Wells, R., Yano, K.M., Zaeschmar, J.R. & Bejder, L.(2023) A deep learning approach to photo–identification demonstrates high performance on two dozen cetacean species. Methods in Ecology and Evolution, 14, 2611–2625. featured on cover\nVivier, F., Wells, R.S., Hill, M.C., Yano, K.M., Bradford, A.L., Leunissen, E.M., Pacini, A., Booth, C.G., Rocho-Levine, J., Currie J.J., Patton, P.T., & Bejder, L. (2023) Quantifying the age-structure of free-ranging delphinid populations: testing the accuracy of Unoccupied Aerial System-photogrammetry. Ecology and Evolution, 13, e10082.\nPatton, P. T., Pacifici, K., & Collazo, J. A. (2022) Modeling and estimating co-occurrence between the invasive Shiny Cowbird and its Puerto Rican hosts. Biological Invasions, 24, 2951–2960"
  },
  {
    "objectID": "cv.html#presentations",
    "href": "cv.html#presentations",
    "title": "Philip T. Patton",
    "section": "Presentations",
    "text": "Presentations\n\nPatton, P.T. Some hierarchical and machine learning models for wildlife science. Invited talk at University of Natural Resources and Life Sciences, Vienna (BOKU). July 2023.\nPatton, P.T. et al. The effect of fully automated photo–identification on mark-recapture estimates. Paper presented at the EURING Analytical Meeting. Montpellier, France. April 2023\nPatton, P.T. Assessing populations of resident cetaceans. HIMB Scholarship Symposium. K=aneohe, Hawaii. April 2022.\nPatton, P. T. & Gardner, B. Misspecifying movement models in spatial capture recapture studies. Paper presented at The Ecological Society of America Conference. Portland, OR, USA. August 2017\nPatton, P. T. et al. Modeling and estimating co–occurrence between generalist brood parasites and host communities. Paper presented at the EURING Analytical Meeting. Barcelona, Spain. June 2017\nPatton, P. T. et al. Multi–species occupancy models that incorporate false positive and false negative sampling errors. Paper presented at The Wildlife Society Conference. Raleigh, NC, USA. October 2016\nPatton, P. T. et al. Joint host–parasite occurrence models can improve predictions and reveal ecological traps. Paper presented at the International Statistical Ecology Conference. Seattle, WA, USA. July 2016"
  },
  {
    "objectID": "cv.html#teaching-experience",
    "href": "cv.html#teaching-experience",
    "title": "Philip T. Patton",
    "section": "Teaching Experience",
    "text": "Teaching Experience\n\nTeaching Assistant, Principles of Wildlife Science (FW 453), North Carolina State, Spring 2016\nTeaching Assistant, Introduction to Probability and Statistics (APM 391), SUNY ESF, Fall 2012\nTutor, Calculus I (APM 105), Academic Support Services, SUNY ESF, 2011 to 2013"
  },
  {
    "objectID": "cv.html#professional-development",
    "href": "cv.html#professional-development",
    "title": "Philip T. Patton",
    "section": "Professional Development",
    "text": "Professional Development\n\nAn Introduction to Close-Kin Mark-Recapture, EURING Analytical Meeting\nC++ Virtual Training, NOAA Fisheries\nBayesian Model Selection and Decision Theory for Ecologists, International Statistical Ecology Conference\nFlexible Programming with NIMBLE, International Statistical Ecology Conference\nIntroduction to Structured Decision Making, National Conservation Training Center"
  },
  {
    "objectID": "cv.html#professional-service",
    "href": "cv.html#professional-service",
    "title": "Philip T. Patton",
    "section": "Professional Service",
    "text": "Professional Service\n\nReferee: Wildlife Society Bulletin, Marine Mammal Science\nMember: British Ecological Society, The Wildlife Society (biometrics working group), The Ecological Society of America (statistical ecology section)\nRepresentative to the Faculty, Marine Biology Graduate Program, University of Hawai`i at Mānoa\nRepresentative to the Graduate Student Organization, Marine Biology Graduate Program, University of Hawai`i at Mānoa"
  },
  {
    "objectID": "scr.html",
    "href": "scr.html",
    "title": "Spatial capture-recapture",
    "section": "",
    "text": "In this notebook, I present an approach to fitting spatial capture-recapture (SCR) models in PyMC. SCR expands upon traditional capture-recapture by incorporating the location of the traps in the analysis. This matters because, typically, animals that live near a particular trap are more likely to be caught in it. In doing so, SCR links individual-level processes to the population-level, expanding the scientific scope of simple designs.\nIn this notebook, I train the simplest possible SCR model, SCR0 (Royle et al. 2013, chap. 5), where the goal is estimating the true population size \\(N\\). Similar to the other closed population notebooks, I do so using parameter-expanded data-augmentation (PX-DA). I also borrow the concept of the detection function from the distance sampling notebook.\nAs a motivating example, I use the ovenbird mist netting dataset provided by Murray Efford via the secr package in R. The design of the study is outlined in Efford, Dawson, and Robbins (2004) and Borchers and Efford (2008). In this dataset, ovenbirds were trapped in 44 mist nets over 8 to 10 consecutive days during the summers of 2005 to 2009.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pytensor.tensor as pt \nimport pymc as pm\nimport arviz as az\nfrom pymc.distributions.dist_math import binomln, logpow\n\n# hyper parameters\nSEED = 42\nRNG = np.random.default_rng(SEED)\nBUFFER = 100\nM = 200\n\n# plotting defaults\nplt.style.use('fivethirtyeight')\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['figure.facecolor'] = 'white'\n\ndef invlogit(x):\n    '''Inverse logit function'''\n    return 1 / (1 + np.exp(-x))\n\ndef euclid_dist(X, S, library='np'):\n    '''Pairwise euclidian distance between points in (M, 2) and (N, 2) arrays'''\n    diff = X[np.newaxis, :, :] - S[:, np.newaxis, :]\n    \n    if library == 'np':\n        return np.sqrt(np.sum(diff ** 2, axis=-1))\n        \n    elif library == 'pm': \n        return pm.math.sqrt(pm.math.sum(diff ** 2, axis=-1))\n\ndef half_normal(d, s, library='np'):\n    '''Half normal detection function.'''\n    if library == 'np':\n        return np.exp( - (d ** 2) / (2 * s ** 2))\n        \n    elif library == 'pm':\n        return pm.math.exp( - (d ** 2) / (2 * s ** 2))\n\ndef exponential(d, s, library='np'):\n    '''Negative exponential detection function.'''    \n    if library == 'np':\n        return np.exp(- d / s)\n        \n    elif library == 'pm':\n        return pm.math.exp(- d / s)\n\n# coordinates for each trap \novenbird_trap = pd.read_csv('ovenbirdtrap.txt', delimiter=' ')\ntrap_count, _ = ovenbird_trap.shape\n\n# information about each trap \ntrap_x = ovenbird_trap.x\ntrap_y = ovenbird_trap.y\nX = ovenbird_trap[['x', 'y']].to_numpy()\n\n# define the state space around the traps\nx_max = trap_x.max() + BUFFER\ny_max = trap_y.max() + BUFFER\nx_min = trap_x.min() - BUFFER\ny_min = trap_y.min() - BUFFER\n\n# plot the trap locations\nfig, ax = plt.subplots(figsize=(4, 4))\n\n# plot the traps\nax.scatter(trap_x, trap_y, marker='x', s=40, linewidth=1.5, color='C1')\nax.set_ylim((y_min, y_max))\nax.set_xlim((x_min, x_max))\n\nax.annotate(\n    '44 nets\\n30m apart', ha='center',\n    xy=(55, -150), xycoords='data', color='black',\n    xytext=(40, 30), textcoords='offset points',\n    arrowprops=dict(arrowstyle=\"-&gt;\", color='black', linewidth=1,\n                    connectionstyle=\"angle3,angleA=90,angleB=0\"))\n\n# aesthetics \nax.set_title('Mist net locations')\nax.grid(False)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: Locations of the mist nets in the ovenbird dataset (Efford, Dawson, and Robbins 2004)\nOne difference between spatial and traditional (non-spatial) capture is the addition of the trap identifier in the capture history. Whereas a traditional capture history is [individual, occasion], a spatial capture history might be [individual, occasion, trap].\nIn the ovenbird example, I ignore the year dimension, pooling parameters across years, which allows for better estimation of the detection parameters. My hack for doing so is treating every band/year combination as a unique individual in a combined year capture history. This is easy to implement, creates an awkward interpretation of \\(N\\) (see below).\n# ovenbird capture history\noven_ch = pd.read_csv('ovenbirdcapt.txt', delimiter=' ')\n\n# create a unique bird/year identifier for each individual\noven_ch['ID'] = oven_ch.groupby(['Year','Band']).ngroup()\noccasion_count = oven_ch.Day.max()\n\n# merge the datasets, making sure that traps with no detections are included \novenbird = (\n    ovenbird_trap.merge(oven_ch[['ID', 'Net', 'Day']], how='left')\n      [['ID', 'Day', 'Net', 'x', 'y']]\n      .sort_values('ID')\n      .reset_index(drop=True)\n)\n\novenbird.head(10)\n\n\n\n\n\n\n\n\nID\nDay\nNet\nx\ny\n\n\n\n\n0\n0.0\n1.0\n2\n-50.0\n-255.0\n\n\n1\n1.0\n9.0\n20\n-50.0\n285.0\n\n\n2\n1.0\n1.0\n15\n-50.0\n135.0\n\n\n3\n2.0\n6.0\n17\n-50.0\n195.0\n\n\n4\n2.0\n9.0\n27\n49.0\n165.0\n\n\n5\n2.0\n1.0\n15\n-50.0\n135.0\n\n\n6\n2.0\n1.0\n14\n-50.0\n105.0\n\n\n7\n3.0\n1.0\n41\n49.0\n-255.0\n\n\n8\n3.0\n3.0\n39\n49.0\n-195.0\n\n\n9\n3.0\n1.0\n42\n49.0\n-285.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Spatial capture-recapture"
    ]
  },
  {
    "objectID": "scr.html#simulation",
    "href": "scr.html#simulation",
    "title": "Spatial capture-recapture",
    "section": "Simulation",
    "text": "Simulation\nBefore estimating the parameters, I perform a small simulation. The simulation starts with a core idea of SCR: the activity center. The activity center \\(\\mathbf{s}_i\\) is the most likely place that you’d find an individual \\(i\\) over the course of the trapping study. In this case, I assume that activity centers are uniformly distributed across the sample space. (The study takes place in homogenous habitat.)\nI compute the probability of detection for individual \\(i\\) at trap \\(j\\) as \\(p_{i,j}=g_0 \\exp(-d_{i,j}^2/2\\sigma^2),\\) where \\(g_0\\) is the probability of detecting an individual when it’s activity center is at the trap, \\(d_{i,j}\\) is the euclidean distance between the trap and the activity center, and \\(\\sigma\\) is the detection range parameter.\n\n# true population size\nN = 150\n\n# simulate activity centers\nsx_true = RNG.uniform(x_min, x_max, N)\nsy_true = RNG.uniform(y_min, y_max, N)\nS_true = np.column_stack((sx_true, sy_true))\n\n# true distance between the trap and the activity centers\nd_true = euclid_dist(X, S_true)\n\n# detection parameters\ng0_true = 0.025     \nsigma_true = 73     \n\n# simulate the number of captures at each trap for each individual\ncapture_probability = g0_true * half_normal(d_true, sigma_true)\nsim_Y = RNG.binomial(occasion_count, capture_probability)\n\n# filter out undetected individuals\nwas_detected = sim_Y.sum(axis=1) &gt; 0\nsim_Y_det = sim_Y[was_detected]\nn_detected = int(was_detected.sum())\n\nFollowing Royle et al. (2013), Chapter 5, I first fit the version of the model where we assume that we know the true population size. In this case, I’m only estimating the detection parameters and the activity center locations.\n\n# upper bound for the uniform prior on sigma\nU_SIGMA = 150\n\nwith pm.Model() as known:\n\n    # priors for the activity centers\n    sx = pm.Uniform('sx', x_min, x_max, shape=n_detected)\n    sy = pm.Uniform('sy', y_min, y_max, shape=n_detected)\n    S = pt.stack([sx, sy], axis=1)\n\n    # priors for the detection parameters\n    g0 = pm.Uniform('g0', 0, 1)\n    sigma = pm.Uniform('sigma', 0, U_SIGMA)\n    \n    # probability of capture for each individual at each trap\n    distance = euclid_dist(X, S, 'pm')\n    p = pm.Deterministic('p', g0 * half_normal(distance, sigma))\n\n    # likelihood\n    pm.Binomial(\n        'y',\n        p=p,\n        n=occasion_count,\n        observed=sim_Y_det\n    )\n\npm.model_to_graphviz(known)\n\n\n\n\n\n\n\nFigure 2: Visual representation of the model where \\(N\\) is known.\n\n\n\n\n\n\nwith known:\n    known_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sx, sy, g0, sigma]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 29 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:29&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(known_idata, var_names=['g0', 'sigma'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ng0\n0.034\n0.004\n0.027\n0.042\n0.000\n0.000\n1291.0\n1947.0\n1.01\n\n\nsigma\n78.971\n5.186\n69.738\n88.585\n0.191\n0.135\n745.0\n1610.0\n1.01\n\n\n\n\n\n\n\n\naz.plot_trace(\n    known_idata, \n    var_names=['g0', 'sigma'],\n    figsize=(8,4),\n    lines=[(\"g0\", {}, [g0_true]), (\"sigma\", {}, [sigma_true])] \n);\n\n\n\n\n\n\n\nFigure 3: Trace plots for model where \\(N\\) is known. The true parameter values are shown by vertical and horizontal lines.\n\n\n\n\n\nThe trace plots show reasonable agreement between the true parameter values and the estimated values, although \\(g_0\\) appears to be overestimated.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Spatial capture-recapture"
    ]
  },
  {
    "objectID": "scr.html#ovenbird-density",
    "href": "scr.html#ovenbird-density",
    "title": "Spatial capture-recapture",
    "section": "Ovenbird density",
    "text": "Ovenbird density\nNow, I estimate the density \\(D\\) for the ovenbird population. Like distance sampling, SCR can robustly estimate the density of the population, regardless of the size of the state space. The difference between the model above and this one is that we use PX-DA to estimate the inclusion probability \\(\\psi,\\) and subsequently \\(N.\\) First, I convert the DataFrame to a (n_detected, n_traps) array of binomial counts.\n\ndef get_Y(ch):\n    '''Get a (individual_count, trap_count) array of detections.'''\n\n    # count the number of detections per individual per trap\n    detection_counts = pd.crosstab(ch.ID, ch.Net, dropna=False)\n\n    # remove the ghost nan individual \n    detection_counts = detection_counts.loc[~detection_counts.index.isna()]\n    \n    Y = detection_counts.to_numpy()\n    return Y\n\nY = get_Y(ovenbird)\ndetected_count, trap_count = Y.shape\n\n# augmented spatial capture histories with all zero histories\nall_zero_history = np.zeros((M - detected_count, trap_count))\nY_augmented = np.row_stack((Y, all_zero_history))\n\nSimilar to the occupancy notebook, I use a custom distribution to model the zero-inflated data. This is necessary because the zero inflation happens at the individual (row) level. This is, in fact, the same distribution as the occupancy model, although including the binomial coefficient.\n\ndef logp(value, n, p, psi):\n    \n    binom = binomln(n, value) + logpow(p, value) + logpow(1 - p, n - value)\n    bin_sum = pm.math.sum(binom, axis=1)\n    bin_exp = pm.math.exp(bin_sum)\n\n    res = pm.math.switch(\n        value.sum(axis=1) &gt; 0,\n        bin_exp * psi,\n        bin_exp * psi + (1 - psi)\n    )\n    \n    return pm.math.log(res)\n\nwith pm.Model() as oven:\n\n    # Priors\n    # activity centers\n    sx = pm.Uniform('sx', x_min, x_max, shape=M)\n    sy = pm.Uniform('sy', y_min, y_max, shape=M)\n    S = pt.stack([sx, sy], axis=1)\n\n    # capture parameters\n    g0 = pm.Uniform('g0', 0, 1, initval=0.05)\n    sigma = pm.Uniform('sigma', 0, U_SIGMA)\n\n    # inclusion probability \n    psi = pm.Uniform('psi', 0, 1)\n\n    # compute the capture probability \n    distance = euclid_dist(X, S, 'pm')\n    p = pm.Deterministic('p', g0 * half_normal(distance, sigma))\n\n    # likelihood \n    pm.CustomDist(\n        'y',\n        occasion_count,\n        p,\n        psi,\n        logp=logp,\n        observed=Y_augmented\n    )\n\npm.model_to_graphviz(oven)\n\n\n\n\n\n\n\nFigure 4: Visual representation of the ovenbird model using data augmentation.\n\n\n\n\n\n\nwith oven:\n    oven_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [sx, sy, g0, sigma, psi]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 56 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:56&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(oven_idata, var_names=['g0', 'sigma', 'psi'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ng0\n0.029\n0.004\n0.022\n0.036\n0.000\n0.000\n1814.0\n2694.0\n1.00\n\n\nsigma\n71.044\n4.694\n62.442\n79.801\n0.167\n0.118\n803.0\n1279.0\n1.01\n\n\npsi\n0.706\n0.056\n0.605\n0.812\n0.001\n0.001\n2983.0\n1997.0\n1.00\n\n\n\n\n\n\n\n\ng0_mle = [0.025]\nsigma_mle = [73]\n\naz.plot_trace(\n    oven_idata, \n    var_names=['g0', 'sigma'],\n    figsize=(8,4),\n    lines=[(\"g0\", {}, [g0_mle]), (\"sigma\", {}, [sigma_mle])] \n);\n\n\n\n\n\n\n\nFigure 5: Trace plots for the ovenbird model using data augmentation. Maximum likelihood estimates are shown by vertical and horizontal lines.\n\n\n\n\n\nThe estimates are quite close to the maximum likelihood estimates, which I estimated using the secr package in R.\nFinally, I estimate density \\(D\\) using the results. As in the closed capture-recapture and distance sampling notebooks, I use the posterior samples of \\(\\psi\\) and \\(M\\) to sample the posterior of \\(N.\\) This \\(N,\\) however, has an awkward interpretation because I pooled across the years by combining all the detection histories. To get around this, I compute the average annual abundance by dividing by the total number of years in the sample. Then, I divide by the area of the state space.\n\ndef sim_N(idata, n, K):\n\n    psi_samps = az.extract(idata).psi.to_numpy()\n    p_samps = az.extract(idata).p\n    p_samps_undet = p_samps[n:, :, :]\n    \n    bin_probs = (1 - p_samps_undet) ** K\n    bin_prod = bin_probs.prod(axis=1)\n    p_included = (bin_prod * psi_samps) / (bin_prod * psi_samps  + (1 - psi_samps))\n    \n    number_undetected = RNG.binomial(1, p_included).sum(axis=0)\n    N_samps = n + number_undetected\n\n    return N_samps\n\n\nN_samps = sim_N(oven_idata, detected_count, occasion_count)\n\n# kludgy way of calculating avergage abundance \nyear_count = 5\naverage_annual_abundance = N_samps // year_count\n\n# area of the state space in terms of hectares \nha = 100 * 100\nmask_area = (x_max - x_min) * (y_max - y_min) / ha\n\n# density \nD_samples = average_annual_abundance / mask_area \nD_mle = 1.262946\n\nfig, ax = plt.subplots(figsize=(4,4))\nax.hist(D_samples, edgecolor='white', bins=13)\nax.axvline(D_mle, linestyle='--',color='C1')\nax.set_xlabel('Ovenbirds per hectare')\nax.set_ylabel('Number of samples')\nax.text(1.4, 800, f'$\\hat{{D}}$={D_samples.mean():.2f}', va='bottom', ha='left')\nplt.show()\n\n\n\n\n\n\n\nFigure 6: Posterior distribution of the density \\(D\\) of ovenbirds. The maximum likelihood estimate is shown by the dotted red line.\n\n\n\n\n\nI also plot the estimated activity centers for every detected individual, as well as the posterior distribution for two of the detected individuals.\n\nsx_samps = az.extract(oven_idata).sx\nsy_samps = az.extract(oven_idata).sy\n\nsx_mean = sx_samps[:detected_count].mean(axis=1)\nsy_mean = sy_samps[:detected_count].mean(axis=1)\n\none = 49\nsx1 = sx_samps[one]\nsy1 = sy_samps[one]\n\ntwo = 2\nsx2 = sx_samps[two]\nsy2 = sy_samps[two]\n\n# plot the trap locations\nfig, (ax0, ax1) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(5, 10),\n                               tight_layout=True)\n\n# plot the traps\nax0.scatter(trap_x, trap_y, marker='x', s=40, linewidth=1.5, color='C1')\nax0.set_ylim((y_min, y_max))\nax0.set_xlim((x_min, x_max))\n\n# plot the mean activity centers\nax0.scatter(sx_mean, sy_mean, marker='o', s=4, color='black')\n\n# aesthetics \nax0.set_title('Estimated activity centers')\nax0.grid(False)\n\n# plot the traps\nax1.scatter(trap_x, trap_y, marker='x', s=40, linewidth=1.5, color='C1')\nax1.set_ylim((y_min, y_max))\nax1.set_xlim((x_min, x_max))\n\n# plot the distributions of the activity centers\nax1.scatter(sx1, sy1, marker='o', s=1, color='gray', alpha=0.2)\nax1.scatter(sx2, sy2, marker='o', s=1, color='gray', alpha=0.2)\n\n# plot the mean\nax1.scatter(sx1.mean(), sy1.mean(), marker='o', s=20, color='black')\nax1.scatter(sx2.mean(), sy2.mean(), marker='o', s=20, color='black')\n\n# add the label\nax1.text(sx1.mean(), sy1.mean() + 5, f'{one}', ha='center', va='bottom')\nax1.text(sx2.mean(), sy2.mean() + 5, f'{two}', ha='center', va='bottom')\n\n# aesthetics \nax1.set_title('Posterior of two activity centers')\nax1.grid(False)\nplt.show()\n\n\n\n\n\n\n\nFigure 7: Estimated activity centers for the detected individuals, and posterior distributions for two of them.\n\n\n\n\n\nFinally, I plot the posterior distribution of the detection function.\n\nxx = np.arange(BUFFER * 2)\n\nsigma_samps = az.extract(oven_idata).sigma.values.flatten()\ng0_samps = az.extract(oven_idata).g0.values.flatten()\n\np_samps = np.array(\n    [g * half_normal(xx, s) for g, s in zip(g0_samps, sigma_samps)]\n)\n\np_mean = p_samps.mean(axis=0)\np_low = np.quantile(p_samps, 0.02, axis=0)\np_high = np.quantile(p_samps, 0.98, axis=0)\n\nfig, ax = plt.subplots(figsize=(5,4))\n\nax.plot(xx, p_mean, '-')\nax.fill_between(xx, p_low, p_high, alpha=0.2)\n\nax.set_title('Detection function')\nax.set_ylabel(r'$p$')\nax.set_xlabel(r'Distance (m)')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 8: Posterior distribution for the detection function. The line represents the posterior mean while the shaded area is the 96% interval.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Spatial capture-recapture"
    ]
  },
  {
    "objectID": "comparison.html",
    "href": "comparison.html",
    "title": "Model comparison",
    "section": "",
    "text": "In this notebook, I demonstrate an approach to model selection in PyMC. To do so, follow the lead of King and Brooks (2008), although not nearly as elegantly. They demonstrate an approach to model selection for a typical suite of closed capture-recapture models. These include the effects of behavior \\(b\\), time \\(t,\\) and individual heterogeneity \\(h\\) on capture probabilities \\(p\\). The eight models considered here are combinations of the three: \\(M_{0},\\) \\(M_{t},\\) \\(M_{b},\\) \\(M_{tb},\\) \\(M_{h},\\) \\(M_{th},\\) \\(M_{bh}\\). The full model, \\(M_{tbh}\\), is\n\\[\n\\begin{equation}\n\\text{logit} \\; p_{it} = \\mu + \\alpha_t + \\beta x_{it} + \\gamma_i,\n\\end{equation}\n\\] where \\(\\mu\\) is the average catchability, \\(\\alpha_t\\) is the effect of each occasion on catchability, \\(\\beta\\) is the behavioral effect, \\(x_{it}\\) indicates whether the individual has been previously caught, and \\(\\gamma_i\\) is the individual random effect such that \\(\\gamma_i \\sim \\text{Normal}(0,\\sigma)\\). Formulating the model this way makes the other models nested subsets of the full model.\nLike King and Brooks (2008), I use the the Moray Firth bottlenose dolphin data as a motivating example. Wilson, Hammond, and Thompson (1999) detected \\(n=56\\) dolphins over the course of \\(T=17\\) boat surveys between May and September 1992. They generated the capture-recapture histories by way of photo-identification, which is near and dear to my heart (and my dissertation).\n\n# libraries \nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport arviz as az\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom pymc.distributions.dist_math import binomln, logpow\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['axes.facecolor'] = 'white'\nplt.rcParams['figure.facecolor'] = 'white'\npal = sns.color_palette(\"Set2\")\nsns.set_palette(pal)\n\n# hyperparameters \nSEED = 808\nRNG = np.random.default_rng(SEED)\n\ndef augment_history(history):\n    '''Augment a capture history with all-zero histories.'''\n    \n    animals_captured, T = history.shape\n\n    # create M - n all zero histories\n    zero_history_count = M - animals_captured\n    zero_history = np.zeros((zero_history_count, T))\n\n    # tack those on to the capture history\n    augmented = np.row_stack((history, zero_history))\n\n    return augmented \n\ndef get_behavior_covariate(history):\n    \n    # note the occasion when each individual was first seen\n    first_seen = (history != 0).argmax(axis=1)\n    \n    # create the covariate for the behavior effect\n    behavior_covariate = np.zeros_like(history)\n    for i, f in enumerate(first_seen):\n        behavior_covariate[i, (f + 1):] = 1\n\n    return behavior_covariate\n\ndef get_occasion_covariate(history):\n\n    _, T = history.shape\n    l = []\n    for t in range(T):\n        oc = np.zeros_like(history)\n        oc[:, t] = 1\n        l.append(oc)\n\n    return np.stack(l, axis=2)\n\ndef sim_N(idata):\n    \n    psi_samps = az.extract(idata).psi.values\n    p_samps = az.extract(idata).p.values\n    not_p = (1 - p_samps)\n    \n    if p_samps.ndim == 1:\n        p_included = psi_samps * (not_p) ** T \n        number_undetected = RNG.binomial(M - n, p_included)\n\n    elif p_samps.ndim == 3:\n        p_included = psi_samps * not_p.prod(axis=1)\n        number_undetected = RNG.binomial(1, p_included).sum(axis=0)\n\n    N = n + number_undetected\n    return N\n\n# convert the dolphin capture history from '1001001' to array\ndolphin = np.loadtxt('firth.txt', dtype=str)\ndolphin = np.array([list(map(int, d)) for d in dolphin])\n\n# augment the capture history with all zero histories\nn, T = dolphin.shape\nM = 500\ndolphin_augmented = augment_history(dolphin)\n\n# covariates for t and b\noccasion_covariate = get_occasion_covariate(dolphin_augmented)\nbehavior_covariate = get_behavior_covariate(dolphin_augmented)\n\nThe discovery curve, the number of unique dolphins encountered as a function of the total number of dolphins encountered, may be flattening. This suggests that, at this point in the study, Wilson, Hammond, and Thompson (1999) may have encountered many of the unique individuals in the population.\n\n# how many dolphins have been seen?\ntotal_seen = dolphin.sum(axis=0).cumsum()\n\n# how many new dolphins have been seen?\nfirst_seen = (dolphin != 0).argmax(axis=1)\nnewbies = [sum(first_seen == t) for t in range(T)]\ntotal_newbies = np.cumsum(newbies)\n\nfig, ax = plt.subplots(figsize=(5, 3.5))\nax.plot(total_seen, total_newbies)\nax.fill_between(total_seen, total_newbies, alpha=0.2)\nax.set_title('Discovery curve')\nax.set_xlabel('Total dolphins')\nax.set_ylabel('Unique dolphins')\nplt.show()\n\n\n\n\n\n\n\nFigure 1: Discovery curve for the Moray Firth bottlenose dolphin surveys (Wilson, Hammond, and Thompson 1999).\n\n\n\n\n\n\nTraining each model\nThis notebook looks messier than the others, in that I train several models with little commentary along the way. In practice, it would probably be better to wrap these up into a function or a class. To complete the model, I used the following priors, \\[\n\\begin{align}\n\\psi &\\sim \\text{Uniform}(0, 1)\\\\\n\\mu &\\sim \\text{Logistic}(0, 1) \\\\\n\\alpha_t &\\sim \\text{Normal}(0, \\sigma_{\\alpha}) \\\\\n\\beta &\\sim \\text{Normal}(0, \\sigma_{\\beta}) \\\\\n\\gamma_i &\\sim \\text{Normal}(0, \\sigma_{\\gamma}) \\\\\n\\sigma_{\\alpha} &\\sim \\text{InverseGamma}(4, 3) \\\\\n\\sigma_{\\beta} &\\sim \\text{InverseGamma}(4, 3) \\\\\n\\sigma_{\\gamma} &\\sim \\text{InverseGamma}(4, 3),\n\\end{align}\n\\] which were also used by King and Brooks (2008). Although note that I used an informative \\(\\text{Beta}(1, 5)\\) prior for \\(\\psi\\) in the full model (see below). I use the same logp seen in the occupancy and closed capture-recapture notebooks, which accounts for row-level zero-inflation. Unlike other notebooks, I did not look at the summaries or the trace plots unless the sampler indicated that it had issues during training.\n\ndef logp(value, n, p, psi):\n    \n    binom = binomln(n, value) + logpow(p, value) + logpow(1 - p, n - value)\n    bin_sum = pm.math.sum(binom, axis=1)\n    bin_exp = pm.math.exp(bin_sum)\n\n    res = pm.math.switch(\n        value.sum(axis=1) &gt; 0,\n        bin_exp * psi,\n        bin_exp * psi + (1 - psi)\n    )\n    \n    return pm.math.log(res)\n\n\nwith pm.Model() as m0:\n\n    # Priors\n    # inclusion\n    psi = pm.Uniform('psi', 0, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # Linear model\n    mu_matrix = (np.ones((T, M)) * mu).T\n    p = pm.Deterministic('p', pm.math.invlogit(mu_matrix))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(m0)\n\n\n\n\n\n\n\nFigure 2: Visual representation of model \\(M_{0}\\).\n\n\n\n\n\n\nwith m0:\n    m0_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nwith pm.Model() as mt:\n\n    # Priors\n    # inclusion\n    psi = pm.Uniform('psi', 0, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # time effect\n    sigma_alpha = pm.InverseGamma('sigma_alpha', 4, 3)\n    alpha = pm.Normal('alpha', 0, tau=1/sigma_alpha, shape=T)\n\n    # Linear model\n    nu = mu + pm.math.dot(occasion_covariate, alpha)\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mt)\n\n\n\n\n\n\n\nFigure 3: Visual representation of model \\(M_t\\).\n\n\n\n\n\n\nwith mt:\n    mt_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_alpha, alpha]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 28 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:27&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nwith pm.Model() as mb:\n\n    # Priors\n    # inclusion\n    psi = pm.Uniform('psi', 0, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n    \n    # behavior effect\n    sigma_beta = pm.InverseGamma('sigma_beta', 4, 3)\n    beta = pm.Normal('beta', 0, tau=1/sigma_beta)\n\n    # Linear model\n    nu = mu + behavior_covariate * beta \n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mb)\n\n\n\n\n\n\n\nFigure 4: Visual representation of model \\(M_b\\).\n\n\n\n\n\n\nwith mb:\n    mb_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_beta, beta]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 13 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:12&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nwith pm.Model() as mtb:\n\n    # Priors\n    # inclusion\n    psi = pm.Uniform('psi', 0, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # time effect\n    sigma_alpha = pm.InverseGamma('sigma_alpha', 4, 3)\n    alpha = pm.Normal('alpha', 0, tau=1/sigma_alpha, shape=T)\n\n    # behavior effect\n    sigma_beta = pm.InverseGamma('sigma_beta', 4, 3)\n    beta = pm.Normal('beta', 0, tau=1/sigma_beta)\n\n    # Linear model\n    nu = mu + pm.math.dot(occasion_covariate, alpha) + behavior_covariate * beta\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mtb)\n\n\n\n\n\n\n\nFigure 5: Visual representation of model \\(M_{tb}\\).\n\n\n\n\n\n\nwith mtb:\n    mtb_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_alpha, alpha, sigma_beta, beta]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 37 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:36&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nwith pm.Model() as mh:\n\n    # Priors\n    # inclusion\n    psi = pm.Uniform('psi', 0, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # individual effect\n    sigma_gamma = pm.InverseGamma('sigma_gamma', 4, 3)\n    gamma = pm.Normal('gamma', 0, tau=1/sigma_gamma, shape=M)\n\n    # Linear model\n    individual_effect = (np.ones((T, M)) * gamma).T\n    nu = mu + individual_effect\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mh)\n\n\n\n\n\n\n\nFigure 6: Visual representation of model \\(M_h\\).\n\n\n\n\n\n\nwith mh:\n    mh_idata = pm.sample(3000, target_accept=0.99)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_gamma, gamma]\nSampling 4 chains for 1_000 tune and 3_000 draw iterations (4_000 + 12_000 draws total) took 92 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 01:32&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(mh_idata, var_names=['psi', 'mu', 'sigma_gamma'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npsi\n0.184\n0.038\n0.122\n0.253\n0.002\n0.001\n608.0\n1078.0\n1.01\n\n\nmu\n-2.784\n0.323\n-3.377\n-2.216\n0.017\n0.012\n390.0\n706.0\n1.02\n\n\nsigma_gamma\n0.777\n0.336\n0.295\n1.396\n0.022\n0.016\n215.0\n468.0\n1.03\n\n\n\n\n\n\n\n\naz.plot_trace(mh_idata, figsize=(8, 6), var_names=['psi', 'mu', 'sigma_gamma']);\n\n\n\n\n\n\n\n\n\nwith pm.Model() as mth:\n\n    # Priors\n    # inclusion\n    psi = pm.Beta('psi', 1, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # time effect\n    sigma_alpha = pm.InverseGamma('sigma_alpha', 4, 3)\n    alpha = pm.Normal('alpha', 0, tau=1/sigma_alpha, shape=T)\n\n    # individual effect\n    sigma_gamma = pm.InverseGamma('sigma_gamma', 4, 3)\n    gamma = pm.Normal('gamma', 0, tau=1/sigma_gamma, shape=M)\n\n    # Linear model\n    individual_effect = (np.ones((T, M)) * gamma).T\n    nu = mu + pm.math.dot(occasion_covariate, alpha) + individual_effect\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mth)\n\n\n\n\n\n\n\nFigure 7: Visual representation of model \\(M_{th}\\).\n\n\n\n\n\n\nwith mth:\n    mth_idata = pm.sample(draws=3000, target_accept=0.95)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_alpha, alpha, sigma_gamma, gamma]\nSampling 4 chains for 1_000 tune and 3_000 draw iterations (4_000 + 12_000 draws total) took 213 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 03:32&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(mth_idata, var_names=['psi', 'mu', 'sigma_alpha', 'sigma_gamma', 'alpha'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npsi\n0.177\n0.035\n0.118\n0.238\n0.001\n0.001\n700.0\n983.0\n1.00\n\n\nmu\n-3.006\n0.401\n-3.775\n-2.289\n0.017\n0.012\n575.0\n900.0\n1.01\n\n\nsigma_alpha\n0.923\n0.358\n0.375\n1.565\n0.004\n0.003\n9159.0\n7416.0\n1.00\n\n\nsigma_gamma\n0.822\n0.357\n0.312\n1.452\n0.023\n0.016\n241.0\n464.0\n1.01\n\n\nalpha[0]\n-1.107\n0.617\n-2.330\n-0.006\n0.006\n0.005\n11171.0\n7188.0\n1.00\n\n\nalpha[1]\n0.563\n0.414\n-0.206\n1.354\n0.005\n0.004\n6862.0\n6647.0\n1.00\n\n\nalpha[2]\n-0.807\n0.557\n-1.889\n0.177\n0.005\n0.005\n10878.0\n8036.0\n1.00\n\n\nalpha[3]\n0.563\n0.407\n-0.210\n1.331\n0.005\n0.003\n7144.0\n7485.0\n1.00\n\n\nalpha[4]\n0.449\n0.415\n-0.339\n1.221\n0.005\n0.004\n7572.0\n7528.0\n1.00\n\n\nalpha[5]\n0.780\n0.401\n0.054\n1.571\n0.005\n0.004\n6376.0\n7094.0\n1.00\n\n\nalpha[6]\n0.177\n0.444\n-0.662\n1.015\n0.005\n0.004\n7483.0\n7897.0\n1.00\n\n\nalpha[7]\n0.026\n0.451\n-0.830\n0.866\n0.005\n0.004\n8610.0\n7551.0\n1.00\n\n\nalpha[8]\n-0.803\n0.562\n-1.839\n0.254\n0.006\n0.005\n10471.0\n7051.0\n1.00\n\n\nalpha[9]\n0.027\n0.455\n-0.847\n0.858\n0.005\n0.004\n8828.0\n8326.0\n1.00\n\n\nalpha[10]\n1.151\n0.382\n0.441\n1.884\n0.005\n0.004\n5996.0\n6314.0\n1.00\n\n\nalpha[11]\n-0.335\n0.496\n-1.274\n0.593\n0.005\n0.005\n8981.0\n7564.0\n1.00\n\n\nalpha[12]\n-1.106\n0.598\n-2.217\n0.008\n0.005\n0.004\n12939.0\n8242.0\n1.00\n\n\nalpha[13]\n-0.151\n0.477\n-1.018\n0.763\n0.005\n0.004\n7860.0\n6848.0\n1.00\n\n\nalpha[14]\n-1.107\n0.612\n-2.290\n-0.007\n0.006\n0.005\n12375.0\n8210.0\n1.00\n\n\nalpha[15]\n1.604\n0.363\n0.920\n2.279\n0.005\n0.003\n5734.0\n7286.0\n1.00\n\n\nalpha[16]\n-0.805\n0.564\n-1.852\n0.234\n0.005\n0.004\n12198.0\n7592.0\n1.00\n\n\n\n\n\n\n\n\naz.plot_trace(mth_idata, figsize=(8, 10),\n              var_names=['psi', 'mu', 'sigma_alpha', 'sigma_gamma', 'alpha']);\n\n\n\n\n\n\n\nFigure 8: Trace plots for model \\(M_{th}\\).\n\n\n\n\n\n\nwith pm.Model() as mbh:\n\n    # Priors\n    # inclusion\n    psi = pm.Beta('psi', 1, 1)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # behavior effect\n    sigma_beta = pm.InverseGamma('sigma_beta', 4, 3)\n    beta = pm.Normal('beta', 0, tau=1/sigma_beta)\n    \n    # individual effect\n    sigma_gamma = pm.InverseGamma('sigma_gamma', 4, 3)\n    gamma = pm.Normal('gamma', 0, tau=1/sigma_gamma, shape=M)\n\n    # Linear model\n    individual_effect = (np.ones((T, M)) * gamma).T\n    nu = mu + behavior_covariate * beta + individual_effect\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mbh)\n\n\n\n\n\n\n\nFigure 9: Visual representation of model \\(M_{bh}\\).\n\n\n\n\n\n\nwith mbh:\n    mbh_idata = pm.sample(draws=3000, target_accept=0.95)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_beta, beta, sigma_gamma, gamma]\nSampling 4 chains for 1_000 tune and 3_000 draw iterations (4_000 + 12_000 draws total) took 359 seconds.\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 05:59&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(mbh_idata, var_names=['psi', 'mu', 'beta', 'sigma_gamma'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npsi\n0.551\n0.190\n0.251\n0.925\n0.010\n0.007\n385.0\n1566.0\n1.00\n\n\nmu\n-3.491\n0.586\n-4.582\n-2.452\n0.035\n0.025\n285.0\n694.0\n1.00\n\n\nbeta\n-1.538\n0.259\n-2.013\n-1.037\n0.006\n0.004\n2013.0\n4830.0\n1.00\n\n\nsigma_gamma\n2.117\n0.772\n0.843\n3.505\n0.050\n0.035\n233.0\n572.0\n1.01\n\n\n\n\n\n\n\n\naz.plot_trace(mbh_idata, figsize=(8, 10),\n              var_names=['psi', 'mu', 'beta', 'sigma_beta', 'sigma_gamma']);\n\n\n\n\n\n\n\n\n\nwith pm.Model() as mtbh:\n\n    # Priors\n    # inclusion\n    psi = pm.Beta('psi', 1, 5)  \n\n    # mean catchability \n    mu = pm.Logistic('mu', 0, 1)\n\n    # time effect\n    sigma_alpha = pm.InverseGamma('sigma_alpha', 4, 3)\n    alpha = pm.Normal('alpha', 0, tau=1/sigma_alpha, shape=T)\n\n    # behavior effect\n    sigma_beta = pm.InverseGamma('sigma_beta', 4, 3)\n    beta = pm.Normal('beta', 0, tau=1/sigma_beta)\n\n    # individual effect\n    sigma_gamma = pm.InverseGamma('sigma_gamma', 4, 3)\n    gamma = pm.Normal('gamma', 0, tau=1/sigma_gamma, shape=M)\n\n    # Linear model\n    individual_effect = (np.ones((T, M)) * gamma).T\n    nu = mu + pm.math.dot(occasion_covariate, alpha) + behavior_covariate * beta + individual_effect\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # Likelihood \n    pm.CustomDist(\n        'y',\n        1,\n        p,\n        psi,\n        logp=logp,\n        observed=dolphin_augmented\n    )\n    \npm.model_to_graphviz(mtbh)\n\n\n\n\n\n\n\nFigure 10: Visual representation of model \\(M_{tbh}\\).\n\n\n\n\n\n\nwith mtbh:\n    mtbh_idata = pm.sample(draws=2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, mu, sigma_alpha, alpha, sigma_beta, beta, sigma_gamma, gamma]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 90 seconds.\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 01:30&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.summary(mtbh_idata, \n           var_names=['psi', 'mu', 'alpha', 'beta', 'sigma_alpha', 'sigma_beta', 'sigma_gamma'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npsi\n0.713\n0.102\n0.522\n0.898\n0.002\n0.001\n3048.0\n4771.0\n1.0\n\n\nmu\n-3.100\n0.466\n-4.020\n-2.262\n0.015\n0.010\n997.0\n2002.0\n1.0\n\n\nalpha[0]\n-3.116\n0.699\n-4.435\n-1.844\n0.011\n0.008\n3818.0\n4897.0\n1.0\n\n\nalpha[1]\n-0.670\n0.509\n-1.608\n0.297\n0.010\n0.007\n2799.0\n3931.0\n1.0\n\n\nalpha[2]\n-1.697\n0.659\n-2.967\n-0.501\n0.010\n0.008\n4092.0\n4887.0\n1.0\n\n\nalpha[3]\n-0.053\n0.488\n-0.969\n0.871\n0.009\n0.006\n3164.0\n4502.0\n1.0\n\n\nalpha[4]\n0.214\n0.481\n-0.677\n1.126\n0.008\n0.006\n3506.0\n4991.0\n1.0\n\n\nalpha[5]\n0.835\n0.451\n-0.030\n1.653\n0.008\n0.006\n3053.0\n4420.0\n1.0\n\n\nalpha[6]\n0.381\n0.499\n-0.537\n1.307\n0.008\n0.005\n4143.0\n4921.0\n1.0\n\n\nalpha[7]\n0.380\n0.509\n-0.627\n1.289\n0.008\n0.006\n3847.0\n4482.0\n1.0\n\n\nalpha[8]\n-0.553\n0.661\n-1.814\n0.665\n0.009\n0.007\n5914.0\n4893.0\n1.0\n\n\nalpha[9]\n0.465\n0.528\n-0.536\n1.436\n0.008\n0.006\n4120.0\n4516.0\n1.0\n\n\nalpha[10]\n1.666\n0.432\n0.837\n2.459\n0.008\n0.006\n2646.0\n4381.0\n1.0\n\n\nalpha[11]\n0.138\n0.562\n-0.936\n1.181\n0.008\n0.006\n5079.0\n5170.0\n1.0\n\n\nalpha[12]\n-0.898\n0.752\n-2.312\n0.477\n0.010\n0.008\n6392.0\n5209.0\n1.0\n\n\nalpha[13]\n0.389\n0.542\n-0.638\n1.390\n0.008\n0.006\n4114.0\n5409.0\n1.0\n\n\nalpha[14]\n-0.868\n0.746\n-2.272\n0.493\n0.009\n0.008\n7017.0\n5038.0\n1.0\n\n\nalpha[15]\n2.242\n0.417\n1.457\n3.003\n0.008\n0.006\n2503.0\n4622.0\n1.0\n\n\nalpha[16]\n-0.257\n0.686\n-1.512\n1.030\n0.009\n0.008\n6241.0\n5109.0\n1.0\n\n\nbeta\n-3.283\n0.388\n-4.001\n-2.549\n0.007\n0.005\n2715.0\n4782.0\n1.0\n\n\nsigma_alpha\n1.555\n0.597\n0.676\n2.669\n0.009\n0.007\n4883.0\n5056.0\n1.0\n\n\nsigma_beta\n2.381\n1.502\n0.610\n4.921\n0.020\n0.015\n8249.0\n5157.0\n1.0\n\n\nsigma_gamma\n2.779\n0.650\n1.681\n4.051\n0.033\n0.023\n383.0\n839.0\n1.0\n\n\n\n\n\n\n\n\naz.plot_trace(mtbh_idata, figsize=(8,14),\n           var_names=['psi', 'mu', 'alpha', 'beta', 'sigma_alpha', 'sigma_beta', 'sigma_gamma']);\n\n\n\n\n\n\n\nFigure 11: Trace plots for the model with \\(M_{tbh}\\).\n\n\n\n\n\nThe trace plots and summary statistics show convergence issues for many of the individual heterogeneity models. The variance parameter, \\(\\sigma_{\\gamma},\\) seems to sample poorly. Further, models with both behavioral and individual effects lead to extremely large estimates of \\(\\psi\\). This appears to happen regardless of the size of the data augmentation \\(M.\\)\nNote that I upped the target_accept value for some models. This slows the sampler, but lowers the risk of divergence.\n\n\nModel comparison\nNext, I select a model for inference using an approximation of leave-one-out (loo) cross-validation (Vehtari, Gelman, and Gabry 2017). This approximation can be calculated using PyMC. To do so, I calculate the log-likelihood for each model, which is added to the InferenceData object. This makes it possible to compare the models using loo and az.compare.\n\nwith m0:\n    pm.compute_log_likelihood(m0_idata)\n\nwith mt:\n    pm.compute_log_likelihood(mt_idata)\n\nwith mb:\n    pm.compute_log_likelihood(mb_idata)\n\nwith mtb:\n    pm.compute_log_likelihood(mtb_idata)\n\nwith mh:\n    pm.compute_log_likelihood(mh_idata)\n\nwith mth:\n    pm.compute_log_likelihood(mth_idata)\n\nwith mbh:\n    pm.compute_log_likelihood(mbh_idata)\n\nwith mtbh:\n    pm.compute_log_likelihood(mtbh_idata)\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:00&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:04&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:03&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03&lt;00:00]\n    \n    \n\n\n\nmodel_dict = {\"m0\": m0_idata, \"mt\": mt_idata, \"mb\": mb_idata, \n              \"mtb\": mtb_idata, \"mh\": mh_idata, \"mth\": mth_idata, \n              \"mbh\": mbh_idata, \"mtbh\": mtbh_idata}\n\ncomparison = az.compare(model_dict)\n\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:805: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:805: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:805: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:805: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:805: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:309: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'True' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:309: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\nThe comparison tools notes issues with several of the models, suggesting a lack of robustness. Inspection of the comparison table shows that the struggling models all include the individual effect \\(h.\\) A more thorough analysis would consider reparameterizing the model, e.g., through the non-centered parameterization. In lieu of that, I simply discard the models that fail this test and re-do the comparison with the passing models.\n\ncomparison.round(2)\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmtbh\n0\n-430.62\n87.06\n0.00\n0.97\n57.18\n0.00\nTrue\nlog\n\n\nmth\n1\n-489.22\n38.02\n58.60\n0.00\n58.89\n11.21\nTrue\nlog\n\n\nmtb\n2\n-493.26\n21.47\n62.64\n0.00\n62.12\n11.43\nTrue\nlog\n\n\nmt\n3\n-493.92\n14.34\n63.30\n0.00\n59.54\n12.50\nFalse\nlog\n\n\nmbh\n4\n-495.19\n68.06\n64.57\n0.00\n60.82\n11.47\nTrue\nlog\n\n\nmh\n5\n-518.62\n25.59\n88.00\n0.03\n61.47\n15.31\nTrue\nlog\n\n\nmb\n6\n-521.53\n5.45\n90.91\n0.00\n63.17\n15.28\nFalse\nlog\n\n\nm0\n7\n-522.55\n2.50\n91.93\n0.00\n62.10\n16.12\nFalse\nlog\n\n\n\n\n\n\n\n\ngood_dict = {\"m0\": m0_idata, \"mt\": mt_idata, \"mb\": mb_idata, \"mtb\": mtb_idata}\ngood_comparison = az.compare(good_dict)\ngood_comparison.round(2)\n\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:805: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:309: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'True' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:309: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmtb\n0\n-493.26\n21.47\n0.00\n0.61\n62.12\n0.00\nTrue\nlog\n\n\nmt\n1\n-493.92\n14.34\n0.66\n0.39\n59.54\n6.77\nFalse\nlog\n\n\nmb\n2\n-521.53\n5.45\n28.28\n0.00\n63.17\n8.61\nFalse\nlog\n\n\nm0\n3\n-522.55\n2.50\n29.29\n0.00\n62.10\n10.41\nFalse\nlog\n\n\n\n\n\n\n\n\naz.plot_compare(good_comparison, figsize=(5, 4));\n\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/plots/backends/matplotlib/compareplot.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  scale = comp_df[\"scale\"][0]\n\n\n\n\n\n\n\n\nFigure 12: Differences in the ELPD criteria, calculated using loo, for each model (Vehtari, Gelman, and Gabry 2017).\n\n\n\n\n\nThe comparison shows that all of the model weight belongs to two models: \\(M_t\\) and \\(M_{tb}.\\)\n\n\nModel averaged predictions\nFinally, we can use the model weights to simulate a weighted posterior of \\(N.\\) To do so, I take a weighted sample of each of the posteriors of \\(N,\\) with the weight dictated by the comparison tool.\n\nposteriors = [sim_N(good_dict[model]) for model in good_dict]\nweights = [good_comparison.loc[model].weight for model in good_dict]\nsample_count = len(posteriors[0])\n\nl = []\nfor w, p in zip(weights, posteriors):\n    weighted_sample = RNG.choice(p, size=int(w * sample_count))\n    l.append(weighted_sample)\n\nweighted_posterior = np.concatenate(l)\n\nfig, (ax0, ax1) = plt.subplots(2, 1, figsize=(7, 6), sharex=True, sharey=True, tight_layout=True)\n\npal = sns.color_palette(\"Set2\")\n\n# labs = [k for k in good_dict.keys()]\nlabs = [r'$M_{0}$', r'$M_{t}$', r'$M_{b}$', r'$M_{tb}$']\nfor i, p in enumerate(posteriors):\n    ax0.hist(p, color=pal[i], edgecolor='white', bins=60, alpha=0.6, label=labs[i])\n\nax0.set_title(r'Posteriors of $N$')\n# ax1.set_title(r'Weighted posterior')\n\nax0.set_xlim((53, 150))\nax0.legend()\n\nax0.set_ylabel('Number of samples')\nax1.set_ylabel('Number of samples')\n\nax1.hist(weighted_posterior, edgecolor='white', bins=60, alpha=0.9, color=pal[6], label='Weighted')\nax1.legend()\n\nplt.show()\n\n\n\n\n\n\n\nFigure 13: Posteriors of \\(N\\) from the four models under consideration (top panel), with the model averaged posterior (bottom panel).\n\n\n\n\n\nWe can also look at the posterior densities of \\(p\\) from Model \\(M_t,\\) the second most weighted model.\n\np_samps = az.extract(mt_idata).p.mean(axis=0)\n\nfig, ax = plt.subplots(figsize=(6, 4))\n\na = 0.4\n# ax[0].set_title(\"Poisson\")\npal = sns.color_palette('viridis', T)\nfor t in range(T):\n    label_idx = t % 2\n    if label_idx == 0:\n        az.plot_dist(p_samps[t], ax=ax, color=pal[t], label=f'$t_{{{t}}}$',\n                     plot_kwargs={'linewidth':3, 'alpha': a})\n    else:\n        az.plot_dist(p_samps[t], ax=ax, color=pal[t],\n                     plot_kwargs={'linewidth':3, 'alpha': a})\n\nax.set_title(r'Posterior densities of $p$ from $M_t$')\nax.set_xlabel(r'$p$')\n\nplt.show()\n\n\n\n\n\n\n\nFigure 14: Posteriors of \\(p\\) from model \\(M_t\\)\n\n\n\n\n\nThis notebook demonstrates a simple way to compare models using leave one out cross-validation (loo) and a classic example from capture-recapture. This is just one way, however, to perform model comparison using PyMC. Perhaps a more effective solution for this problem would be placing a shrinkage prior on the \\(\\sigma\\) parameters.\n\n\n\n\n\nReferences\n\nKing, Ruth, and SP2526632 Brooks. 2008. “On the Bayesian Estimation of a Closed Population Size in the Presence of Heterogeneity and Model Uncertainty.” Biometrics 64 (3): 816–24.\n\n\nVehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.” Statistics and Computing 27: 1413–32.\n\n\nWilson, Ben, Philip S Hammond, and Paul M Thompson. 1999. “Estimating Size and Assessing Trends in a Coastal Bottlenose Dolphin Population.” Ecological Applications 9 (1): 288–300.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Model comparison"
    ]
  },
  {
    "objectID": "occupancy.html",
    "href": "occupancy.html",
    "title": "Occupancy models",
    "section": "",
    "text": "In this notebook, I demonstrate how to fit static site-occupancy models in PyMC (Royle and Dorazio 2008, chap. 3). The standard site-occupancy model models binary detection/non-detection data \\(y_{j,k}\\) for repeated surveys \\(k=1,2,\\dots,K\\) at sites \\(j=1,2,\\dots,J.\\) The species is present at the sites when \\(z_j=1,\\) and absent otherwise. We assume that our probability of detecting the species given that the site is occupied is \\(P(y_{j,k}|z_j=1)=p,\\) and zero when the site is unoccupied. The probability of occurrence, which is typically the parameter of interest, is \\(P(z_{j}=1)=\\psi.\\) As such, we can think of this as a zero-inflated binomial model, where \\[\n\\begin{align}\n&y_j \\sim\n\\begin{cases}\n    0,   & \\text{if } z_j = 0 \\\\\n    \\text{Binomial}(K, p),   & \\text{if } z_j = 1\n\\end{cases} \\\\\n&z_j \\sim \\text{Bernoulli}(\\psi)\n\\end{align},\n\\] which assumes a constant occurrence probability across sites and a constant detection probability. I start with this simple model, then add site- and visit-level covariates later.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occupancy.html#estimating-parameters-with-pymc",
    "href": "occupancy.html#estimating-parameters-with-pymc",
    "title": "Occupancy models",
    "section": "Estimating parameters with PyMC",
    "text": "Estimating parameters with PyMC\nNext, I use PyMC to train the occupancy model with the simulated data. First, similar to JAGS and Stan, the model must be specified using the PyMC syntax. This is done using a context manager in Python, essentially, a with statement. This creates a Model object.\n\nwith pm.Model() as constant:\n\n    # priors for the detetion and occurrence probabilities\\\n    psi = pm.Uniform('psi', 0, 1)\n    p = pm.Uniform('p', 0, 1)\n\n    # likelihood for the summarized data\n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=visit_count, \n                            observed=y_summarized)\n\nIn JAGS, the prior for \\(p\\) would be specified as p ~ dunif(0, 1). The PyMC equivalent is p = pm.Uniform('p', 0, 1). This could, alternatively, be specified as p = pm.Uniform('detection probability', 0, 1). For the likelihood, I use PyMC’s built-in ZeroInflatedBinomial distribution. We tell PyMC that this is an observed random variable by supplying data to the observed argument. PyMC also has handy tools for visualizing the model.\n\npm.model_to_graphviz(constant)\n\n\n\n\n\n\n\nFigure 1: Visual representation of model \\(p(\\cdot)\\psi(\\cdot).\\) MarginalMixture refers to the zero-inflated binomial distribution.\n\n\n\n\n\nNow I can sample from the posterior. Again, I use the context manager, this time referring to the model by name. It’s typical to name the output with idata because, by default, PyMC returns an object of class InferenceData from the Arviz package. Arviz is similar to the coda package for R.\n\nwith constant:\n    constant_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [psi, p]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nPyMC will try to use the No-U-Turn Sampler (NUTS) whenever possible. As you can see, it samples the posterior quickly. I can plot the output using the az.plot_trace(), supplying the true values for \\(p\\) and \\(\\psi\\) for comparizon. I can also look at a tabular summary using az.summary().\n\naz.plot_trace(\n    constant_idata,\n    compact=True,\n    figsize=(8,4),\n    lines=[(\"psi\", {}, [psi_true]), (\"p\", {}, [p_true])] \n);\n\n\n\n\n\n\n\nFigure 2: Traceplots for the \\(p(\\cdot)\\psi(\\cdot)\\) model. The true parameter values are shown by vertical and horizontal lines.\n\n\n\n\n\n\naz.summary(constant_idata)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npsi\n0.8\n0.042\n0.719\n0.878\n0.001\n0.001\n1858.0\n1914.0\n1.0\n\n\np\n0.5\n0.030\n0.444\n0.557\n0.001\n0.001\n1769.0\n2256.0\n1.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occupancy.html#adding-site-covariates",
    "href": "occupancy.html#adding-site-covariates",
    "title": "Occupancy models",
    "section": "Adding site covariates",
    "text": "Adding site covariates\nNext, I add in some realism by simulating a site-level covariate \\(x\\) that affects the occurrence probability. I model this effect with a logit-linear model, i.e., \\(\\psi_j=\\text{logit}^{-1}(\\beta_0 + \\beta_1 x_j).\\)\n\n## ecological model\n\n# true parameter values\nbeta0_true = -1\nbeta1_true = 3\n\n# covariates \nx = scale(rng.uniform(size=site_count))\n\n# linear model\nmu_true = beta0_true + beta1_true * x\npsi_true = invlogit(mu_true)\n\n# simulate occurrence state\nz_true = rng.binomial(1, psi_true)\n\n## detection model\n\n# true parameter values\np_true = 0.75\n\n# simulate detection\ny = sim_y(p_true, z_true, site_count, visit_count)\n\n# vector with the number of detections at each site \ny_summarized = y.sum(axis=1)\n\n# detection data at the first five sites \ny[:5]\n\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]])\n\n\nAgain, I specify the model with PyMC. Like JAGS, the random variables can be manipulated, as in a linear model with \\(x_j.\\) These behave like numpy arrays, meaning that vectorized operations and broadcasting are available. To monitor the output of these manipulations, use the pm.Deterministic class. In this case, I am monitoring the site level occurrence probability \\(\\psi_j.\\)\n\nwith pm.Model() as psix:\n\n    # occurrence process \n    # priors \n    beta0 = pm.Normal(\"beta0\", mu=0, sigma=2)\n    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n    \n    # linear model\n    mu = beta0 + beta1 * x\n    psi = pm.Deterministic(\"psi\", pm.math.invlogit(mu))\n\n    # detection process\n    # prior\n    p = pm.Uniform('p', 0, 1)\n\n    # likelihood for the summarized data\n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=visit_count, \n                            observed=y_summarized)\n\npm.model_to_graphviz(psix)\n\n\n\n\n\n\n\nFigure 3: Visual representation of model \\(p(\\cdot)\\psi(x).\\) MarginalMixture refers to the zero-inflated binomial distribution.\n\n\n\n\n\n\nwith psix:\n    psix_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [beta0, beta1, p]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_trace(\n    psix_idata,\n    figsize=(8,6),\n    var_names=['beta0', 'beta1', 'p'],\n    lines=[(\"beta0\", {}, [beta0_true]), (\"beta1\", {}, [beta1_true]), \n           ('p', {}, [p_true])]\n);\n\n\n\n\nTraceplots for the \\(p(\\cdot)\\psi(x)\\) model. The true parameter values are shown by vertical and horizontal lines\n\n\n\n\n\naz.summary(psix_idata, var_names=['beta0', 'beta1', 'p'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta0\n-1.245\n0.265\n-1.772\n-0.782\n0.005\n0.004\n2565.0\n2402.0\n1.0\n\n\nbeta1\n2.856\n0.410\n2.106\n3.626\n0.008\n0.006\n2688.0\n2590.0\n1.0\n\n\np\n0.744\n0.032\n0.684\n0.804\n0.001\n0.000\n3893.0\n2554.0\n1.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occupancy.html#adding-visit-covariates",
    "href": "occupancy.html#adding-visit-covariates",
    "title": "Occupancy models",
    "section": "Adding visit covariates",
    "text": "Adding visit covariates\nFinally, I add in visit-level covariate \\(w_{j,k}\\) that affects detection.\n\n## ecological model\n\n# true parameter values\nbeta0_true = -1\nbeta1_true = 3\n\n# covariates \nx = scale(rng.uniform(size=site_count))\n\n# linear model\nmu_true = beta0_true + beta1_true * x\npsi_true = invlogit(mu_true)\n\n# simulate occurrence state\nz_true = rng.binomial(1, psi_true)\n\n# true parameter values\nalpha0_true = 1\nalpha1_true = -3\n\n# covariates\nw = rng.uniform(size=site_count * visit_count).reshape(site_count, visit_count)\nw = scale(w)\n\n# linear model\nnu_true = alpha0_true + alpha1_true * w\np_true = invlogit(nu_true)\n\n# simulate detection\ny = sim_y(p_true, z_true, site_count, visit_count)\n\ny[:5]\n\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 1, 1],\n       [1, 1, 0],\n       [0, 0, 0]])\n\n\nOur PyMC code will need to be a little uglier now. I could write the model in terms of the latent occurrence state \\(z_j.\\) The NUTS sampler, however, does not jive with discrete latent states. As such, PyMC will assign it to a binary Gibbs sampler by default, which works, albeit painfully slowly.\nSince I am impatient, I instead use the marginalized version of the model, that is, a model that does not include the discrete latent states. To do this in PyMC, I use the CustomDist class. This requires, first, defining the log probability of the distribution, logp, given the data and it’s parameters. We can write logp using the likelihood of the occupancy model, \\[\nP(\\mathbf{y}_j)=\n\\begin{cases}\n    P(\\mathbf{y}_j | z_j = 1)\\; \\psi_j \\; + \\; (1 - \\psi_j),   & \\text{if } \\mathbf{y}_j = \\mathbf{0}\\\\\n    P(\\mathbf{y}_j | z_j = 1)\\; \\psi_j,  & \\text{otherwise}\n\\end{cases}\n\\] where \\(P(\\mathbf{y}_j | z_j = 1) = \\prod_j p_{j,k}^{y_{j,k}} (1-p_{j,k})^{(1-y_{j,k})}\\) (Royle and Dorazio 2008). To do this in PyMC, I rely on the pm.math.switch function, which is similar to ifelse() in R or np.where().\n\n# likelihood for y data\ndef logp(x, p, psi):\n    '''Computes the log-likelihood for an occupancy model\n\n    Args: \n        x: (site_count x visit_count) array with binary detection data\n        p: (site_count x visit_count) array of probabilities\n        p: site_count vector of probabilities\n    '''\n    \n    bern = (p ** x) * ((1 - p) ** (1 - x))\n    bern_prod = pm.math.prod(bern, axis=1)\n    \n    res = pm.math.switch(\n        x.sum(axis=1) &gt; 0,\n        bern_prod * psi,\n        bern_prod * psi + (1 - psi)\n    )\n    \n    return pm.math.log(res)\n\nThen, I simply provide this function as an argument to the CustomDist class in our PyMC model. Note that we have to tell CustomDist how many dimensions each parameter has via the ndims_params argument. In this case, p has the same number of dimensions of Y (2), while psi has one dimension since it is vector of length site_count.\n\nwith pm.Model() as marginal:\n\n    # occurrence process \n    # priors \n    beta0 = pm.Normal(\"beta0\", mu=0, sigma=2)\n    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n    \n    # linear model\n    mu = beta0 + beta1 * x\n    psi = pm.Deterministic(\"psi\", pm.math.invlogit(mu))\n\n    # detection process\n    # priors\n    alpha0 = pm.Normal('alpha0', mu=0, sigma=2)\n    alpha1 = pm.Normal('alpha1', mu=0, sigma=2)\n\n    # linear model\n    nu = alpha0 + alpha1 * w\n    p = pm.Deterministic('p', pm.math.invlogit(nu))\n\n    # likelihood\n    pm.CustomDist(\n        'y',\n        p,\n        psi,\n        logp=logp,\n        observed=y,\n        ndims_params=[2, 1]\n    )\n\npm.model_to_graphviz(marginal)\n\n\n\n\n\n\n\nFigure 4: Visual representation of the \\(p(w)\\psi(w)\\) model.\n\n\n\n\n\n\nwith marginal:\n    marginal_idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [beta0, beta1, alpha0, alpha1]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_trace(\n    marginal_idata,\n    figsize=(8,6), \n    var_names=['beta0', 'beta1', 'alpha0', 'alpha1'],\n    lines=[(\"beta0\", {}, [beta0_true]), (\"beta1\", {}, [beta1_true]), \n           ('alpha0', {}, [alpha0_true]), ('alpha1', {}, [alpha1_true])]\n);\n\n\n\n\n\n\n\nFigure 5: Tracepots for the \\(p(w)\\psi(x)\\) model. The true parameter values are shown by vertical and horizontal lines\n\n\n\n\n\n\naz.summary(marginal_idata, var_names=['beta0', 'beta1', 'alpha0', 'alpha1'])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta0\n-0.745\n0.242\n-1.183\n-0.268\n0.004\n0.003\n3415.0\n3138.0\n1.0\n\n\nbeta1\n2.784\n0.389\n2.084\n3.501\n0.007\n0.005\n3376.0\n2753.0\n1.0\n\n\nalpha0\n1.400\n0.271\n0.850\n1.882\n0.005\n0.003\n3293.0\n2650.0\n1.0\n\n\nalpha1\n-3.087\n0.381\n-3.805\n-2.395\n0.007\n0.005\n3108.0\n2900.0\n1.0",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  },
  {
    "objectID": "occupancy.html#model-comparison",
    "href": "occupancy.html#model-comparison",
    "title": "Occupancy models",
    "section": "Model comparison",
    "text": "Model comparison\nPyMC also has handy tools for model comparison. I demonstrate these by fitting a model to the warbler data with a constant probability of detection.\n\nY_sum = Y.sum(axis=1)\n\nwith pm.Model(coords=coords) as warbler_constantp:\n\n    # occurrence process priors \n    Beta = pm.Normal(\"Beta\", mu=0, sigma=2, dims=\"beta_coefs\")\n    \n    # linear model\n    mu = pm.math.dot(X, Beta)\n    psi = pm.Deterministic(\"psi\", pm.math.invlogit(mu))\n\n    # detection process priors\n    p = pm.Uniform('p', 0, 1)\n\n    # likelihood\n    pm.ZeroInflatedBinomial('y', p=p, psi=psi, n=J, observed=Y_sum)\n\npm.model_to_graphviz(warbler_constantp)\n\n\n\n\n\n\n\nFigure 9: Visual representaion of the warbler occupancy model with constant \\(p.\\)\n\n\n\n\n\n\nwith warbler_constantp:\n    warbler_constantp_idata = pm.sample(4000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Beta, p]\nSampling 4 chains for 1_000 tune and 4_000 draw iterations (4_000 + 16_000 draws total) took 5 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [20000/20000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nNext, I caclculate the leave-one-out (loo) cross-validation score for each model (Vehtari, Gelman, and Gabry 2017). This involves first computing the log likelihood for each model.\n\nwith warbler:\n    pm.compute_log_likelihood(warbler_idata)\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 00:00&lt;00:00]\n    \n    \n\n\n\nwarbler_loo = az.loo(warbler_idata)\n\nwarbler_loo\n\nComputed from 16000 posterior samples and 37 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -54.38     7.36\np_loo        6.18        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)       37  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nwith warbler_constantp:\n    pm.compute_log_likelihood(warbler_constantp_idata)\n\n\n\n\n\n\n    \n      \n      100.00% [16000/16000 00:00&lt;00:00]\n    \n    \n\n\n\nwarbler_constantp_loo = az.loo(warbler_constantp_idata)\n\nwarbler_constantp_loo\n\nComputed from 16000 posterior samples and 37 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -39.29     5.10\np_loo        3.75        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)       37  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\nArviz has handy tools for comparing the results. First, I generate a tabular summary.\n\ndf_comp_loo = az.compare({r\"$p(visit,wheight)$\": warbler_idata, \n                          r\"$p(\\cdot)$\": warbler_constantp_idata})\ndf_comp_loo\n\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:309: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/stats/stats.py:309: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\n$p(\\cdot)$\n0\n-39.291887\n3.752913\n0.000000\n1.000000e+00\n5.096256\n0.000000\nFalse\nlog\n\n\n$p(visit,wheight)$\n1\n-54.381840\n6.181580\n15.089953\n8.881784e-14\n7.363060\n4.177454\nFalse\nlog\n\n\n\n\n\n\n\nThis indicates that the \\(p(\\cdot)\\) model is favored over the \\(p(visit,wheight)\\) model.\nArviz also generates plots for these comparisons.\n\naz.plot_compare(df_comp_loo, insample_dev=False);\n\n/Users/philtpatton/miniforge3/envs/pymc/lib/python3.11/site-packages/arviz/plots/backends/matplotlib/compareplot.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  scale = comp_df[\"scale\"][0]\n\n\n\n\n\n\n\n\nFigure 10: Comparison between the \\(p(visit,wheight)\\) and the \\(p(\\cdot)\\) models in terms of loo.",
    "crumbs": [
      "Notebooks",
      "PyMC",
      "Occupancy"
    ]
  }
]